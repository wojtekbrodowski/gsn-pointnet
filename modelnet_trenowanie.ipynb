{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WjtBCQQ9gzIR"
   },
   "outputs": [],
   "source": [
    "!pip install ipdb -Uqq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "3T1lRg05bJCu"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import ipdb\n",
    "\n",
    "class STN3d(nn.Module):\n",
    "    def __init__(self, channel):\n",
    "        super(STN3d, self).__init__()\n",
    "        self.debug1='debug1'\n",
    "        print('debug1')\n",
    "        #ipdb.set_trace(context=5)\n",
    "        self.conv1 = torch.nn.Conv1d(channel, 64, 1)\n",
    "        print('debug2')\n",
    "        #ipdb.set_trace(context=5)\n",
    "        self.conv2 = torch.nn.Conv1d(64, 128, 1)\n",
    "        self.conv3 = torch.nn.Conv1d(128, 1024, 1)\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 9)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(64) #To jest ta normalizacja odchylenia i sredniej (?1)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "        self.bn4 = nn.BatchNorm1d(512)\n",
    "        self.bn5 = nn.BatchNorm1d(256)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        #ipdb.set_trace(context=5)\n",
    "        batchsize = x.size()[0]\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = torch.max(x, 2, keepdim=True)[0]\n",
    "        x = x.view(-1, 1024) #to jest jakiÅ› resize...(?2)\n",
    "\n",
    "        x = F.relu(self.bn4(self.fc1(x)))\n",
    "        x = F.relu(self.bn5(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        #ipdb.set_trace(context=5)\n",
    "        iden = Variable(torch.from_numpy(np.array([1, 0, 0, 0, 1, 0, 0, 0, 1]).astype(np.float32))).view(1, 9).repeat(\n",
    "            batchsize, 1)\n",
    "        if x.is_cuda:\n",
    "            iden = iden.cuda()\n",
    "        x = x + iden\n",
    "        x = x.view(-1, 3, 3)\n",
    "        return x\n",
    "\n",
    "class STNkd(nn.Module):\n",
    "    def __init__(self, k=64):\n",
    "        super(STNkd, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv1d(k, 64, 1)\n",
    "        self.conv2 = torch.nn.Conv1d(64, 128, 1)\n",
    "        self.conv3 = torch.nn.Conv1d(128, 1024, 1)\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, k*k)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "        self.bn4 = nn.BatchNorm1d(512)\n",
    "        self.bn5 = nn.BatchNorm1d(256)\n",
    "\n",
    "        self.k = k\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.size()[0]\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = torch.max(x, 2, keepdim=True)[0]\n",
    "        x = x.view(-1, 1024)\n",
    "\n",
    "        x = F.relu(self.bn4(self.fc1(x)))\n",
    "        x = F.relu(self.bn5(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        iden = Variable(torch.from_numpy(np.eye(self.k).flatten().astype(np.float32))).view(1,self.k*self.k).repeat(batchsize,1)\n",
    "        if x.is_cuda:\n",
    "            iden = iden.cuda()\n",
    "        x = x + iden\n",
    "        x = x.view(-1, self.k, self.k)\n",
    "        return x\n",
    "\n",
    "class PointNetfeat(nn.Module):\n",
    "    def __init__(self, global_feat = True, feature_transform = False):\n",
    "        super(PointNetfeat, self).__init__()\n",
    "        self.stn = STN3d(channel=3)\n",
    "        #self.stn = STN3d()\n",
    "        self.conv1 = torch.nn.Conv1d(3, 64, 1)\n",
    "        self.conv2 = torch.nn.Conv1d(64, 128, 1)\n",
    "        self.conv3 = torch.nn.Conv1d(128, 1024, 1)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "        self.global_feat = global_feat\n",
    "        self.feature_transform = feature_transform\n",
    "        if self.feature_transform:\n",
    "            self.fstn = STNkd(k=64)\n",
    "\n",
    "    def forward(self, x):\n",
    "        n_pts = x.size()[2]\n",
    "        trans = self.stn(x)\n",
    "        x = x.transpose(2, 1)\n",
    "        x = torch.bmm(x, trans)\n",
    "        x = x.transpose(2, 1)\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "\n",
    "        if self.feature_transform:\n",
    "            trans_feat = self.fstn(x)\n",
    "            x = x.transpose(2,1)\n",
    "            x = torch.bmm(x, trans_feat)\n",
    "            x = x.transpose(2,1)\n",
    "        else:\n",
    "            trans_feat = None\n",
    "\n",
    "        pointfeat = x\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.bn3(self.conv3(x))\n",
    "        x = torch.max(x, 2, keepdim=True)[0]\n",
    "        x = x.view(-1, 1024)\n",
    "        if self.global_feat:\n",
    "            return x, trans, trans_feat\n",
    "        else:\n",
    "            x = x.view(-1, 1024, 1).repeat(1, 1, n_pts)\n",
    "            return torch.cat([x, pointfeat], 1), trans, trans_feat\n",
    "\n",
    "class PointNetCls(nn.Module):\n",
    "    def __init__(self, k=2, feature_transform=False):\n",
    "        super(PointNetCls, self).__init__()\n",
    "        self.feature_transform = feature_transform\n",
    "        self.feat = PointNetfeat(global_feat=True, feature_transform=feature_transform)\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, k)\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, trans, trans_feat = self.feat(x)\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = F.relu(self.bn2(self.dropout(self.fc2(x))))\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x, dim=1), trans, trans_feat\n",
    "\n",
    "class PointNetDenseCls(nn.Module):\n",
    "    def __init__(self, k = 2, feature_transform=False):\n",
    "        super(PointNetDenseCls, self).__init__()\n",
    "        self.k = k\n",
    "        self.feature_transform=feature_transform\n",
    "        self.feat = PointNetfeat(global_feat=False, feature_transform=feature_transform)\n",
    "        self.conv1 = torch.nn.Conv1d(1088, 512, 1)\n",
    "        self.conv2 = torch.nn.Conv1d(512, 256, 1)\n",
    "        self.conv3 = torch.nn.Conv1d(256, 128, 1)\n",
    "        self.conv4 = torch.nn.Conv1d(128, self.k, 1)\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.size()[0]\n",
    "        n_pts = x.size()[2]\n",
    "        x, trans, trans_feat = self.feat(x)\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.conv4(x)\n",
    "        x = x.transpose(2,1).contiguous()\n",
    "        x = F.log_softmax(x.view(-1,self.k), dim=-1)\n",
    "        x = x.view(batchsize, n_pts, self.k)\n",
    "        return x, trans, trans_feat\n",
    "\n",
    "def feature_transform_regularizer(trans):\n",
    "    d = trans.size()[1]\n",
    "    batchsize = trans.size()[0]\n",
    "    I = torch.eye(d)[None, :, :]\n",
    "    if trans.is_cuda:\n",
    "        I = I.cuda()\n",
    "    loss = torch.mean(torch.norm(torch.bmm(trans, trans.transpose(2,1)) - I, dim=(1,2)))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jEopUc4tn7rS",
    "outputId": "3dfd48e5-6d9e-4cce-80cc-54014a115c8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting plyfile\n",
      "  Downloading plyfile-0.7.4-py3-none-any.whl (39 kB)\n",
      "Requirement already satisfied: numpy>=1.8 in /usr/local/lib/python3.8/dist-packages (from plyfile) (1.21.6)\n",
      "Installing collected packages: plyfile\n",
      "Successfully installed plyfile-0.7.4\n"
     ]
    }
   ],
   "source": [
    "!pip install plyfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kTY2vmIvo-BU",
    "outputId": "6defb867-4381-42a2-b67c-831345fc7b6f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%shell\n",
    "mkdir ./misc\n",
    "echo \"Airplane\t4\n",
    "Bag\t2\n",
    "Cap\t2\n",
    "Car\t4\n",
    "Chair\t4\n",
    "Earphone\t3\n",
    "Guitar\t3\n",
    "Knife\t2\n",
    "Lamp\t4\n",
    "Laptop\t2\n",
    "Motorbike\t6\n",
    "Mug\t2\n",
    "Pistol\t3\n",
    "Rocket\t3\n",
    "Skateboard\t3\n",
    "Table\t3\" > ./misc/num_seg_classes.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cmooTYS_psF2",
    "outputId": "63c5e8ce-1f7c-4e4a-b748-1b450511c83d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%shell\n",
    "echo \"airplane\t0\n",
    "bathtub\t1\n",
    "bed\t2\n",
    "bench\t3\n",
    "bookshelf\t4\n",
    "bottle\t5\n",
    "bowl\t6\n",
    "car\t7\n",
    "chair\t8\n",
    "cone\t9\n",
    "cup\t10\n",
    "curtain\t11\n",
    "desk\t12\n",
    "door\t13\n",
    "dresser\t14\n",
    "flower_pot\t15\n",
    "glass_box\t16\n",
    "guitar\t17\n",
    "keyboard\t18\n",
    "lamp\t19\n",
    "laptop\t20\n",
    "mantel\t21\n",
    "monitor\t22\n",
    "night_stand\t23\n",
    "person\t24\n",
    "piano\t25\n",
    "plant\t26\n",
    "radio\t27\n",
    "range_hood\t28\n",
    "sink\t29\n",
    "sofa\t30\n",
    "stairs\t31\n",
    "stool\t32\n",
    "table\t33\n",
    "tent\t34\n",
    "toilet\t35\n",
    "tv_stand\t36\n",
    "vase\t37\n",
    "wardrobe\t38\n",
    "xbox\t39\" > ./misc/modelnet_id.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t5ZzJxda71pV"
   },
   "outputs": [],
   "source": [
    "%%shell\n",
    "wget https://shapenet.cs.stanford.edu/media/modelnet40_ply_hdf5_2048.zip --no-check-certificate\n",
    "unzip modelnet40_ply_hdf5_2048.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LNpd19II--vf"
   },
   "outputs": [],
   "source": [
    "%%shell\n",
    "wget http://modelnet.cs.princeton.edu/ModelNet40.zip\n",
    "unzip ModelNet40.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kr-R74wmyaka"
   },
   "outputs": [],
   "source": [
    "%%shell\n",
    "wget https://shapenet.cs.stanford.edu/ericyi/shapenetcore_partanno_segmentation_benchmark_v0.zip --no-check-certificate\n",
    "unzip shapenetcore_partanno_segmentation_benchmark_v0.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "p9WzFLbwoTkD"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch.utils.data as data\n",
    "import os\n",
    "import os.path\n",
    "import torch\n",
    "import numpy as np\n",
    "import sys\n",
    "from tqdm import tqdm \n",
    "import json\n",
    "from plyfile import PlyData, PlyElement\n",
    "\n",
    "def get_segmentation_classes(root):\n",
    "    catfile = os.path.join(root, 'synsetoffset2category.txt')\n",
    "    cat = {}\n",
    "    meta = {}\n",
    "\n",
    "    with open(catfile, 'r') as f:\n",
    "        for line in f:\n",
    "            ls = line.strip().split()\n",
    "            cat[ls[0]] = ls[1]\n",
    "\n",
    "    for item in cat:\n",
    "        dir_seg = os.path.join(root, cat[item], 'points_label')\n",
    "        dir_point = os.path.join(root, cat[item], 'points')\n",
    "        fns = sorted(os.listdir(dir_point))\n",
    "        meta[item] = []\n",
    "        for fn in fns:\n",
    "            token = (os.path.splitext(os.path.basename(fn))[0])\n",
    "            meta[item].append((os.path.join(dir_point, token + '.pts'), os.path.join(dir_seg, token + '.seg')))\n",
    "    \n",
    "    with open('./misc/num_seg_classes.txt', 'w') as f:\n",
    "        for item in cat:\n",
    "            datapath = []\n",
    "            num_seg_classes = 0\n",
    "            for fn in meta[item]:\n",
    "                datapath.append((item, fn[0], fn[1]))\n",
    "\n",
    "            for i in tqdm(range(len(datapath))):\n",
    "                l = len(np.unique(np.loadtxt(datapath[i][-1]).astype(np.uint8)))\n",
    "                if l > num_seg_classes:\n",
    "                    num_seg_classes = l\n",
    "\n",
    "            print(\"category {} num segmentation classes {}\".format(item, num_seg_classes))\n",
    "            f.write(\"{}\\t{}\\n\".format(item, num_seg_classes))\n",
    "\n",
    "def gen_modelnet_id(root):\n",
    "    classes = []\n",
    "    with open(os.path.join(root, 'train.txt'), 'r') as f:\n",
    "        for line in f:\n",
    "            classes.append(line.strip().split('/')[0])\n",
    "    classes = np.unique(classes)\n",
    "    with open('./misc/modelnet_id.txt', 'w') as f:\n",
    "        for i in range(len(classes)):\n",
    "            f.write('{}\\t{}\\n'.format(classes[i], i))\n",
    "\n",
    "class ShapeNetDataset(data.Dataset):\n",
    "    def __init__(self,\n",
    "                 root,\n",
    "                 npoints=2500,\n",
    "                 classification=False,\n",
    "                 class_choice=None,\n",
    "                 split='train',\n",
    "                 data_augmentation=True):\n",
    "        self.npoints = npoints\n",
    "        self.root = root\n",
    "        self.catfile = os.path.join(self.root, 'synsetoffset2category.txt')\n",
    "        self.cat = {}\n",
    "        self.data_augmentation = data_augmentation\n",
    "        self.classification = classification\n",
    "        self.seg_classes = {}\n",
    "        \n",
    "        with open(self.catfile, 'r') as f:\n",
    "            for line in f:\n",
    "                ls = line.strip().split()\n",
    "                self.cat[ls[0]] = ls[1]\n",
    "        #print(self.cat)\n",
    "        if not class_choice is None:\n",
    "            self.cat = {k: v for k, v in self.cat.items() if k in class_choice}\n",
    "\n",
    "        self.id2cat = {v: k for k, v in self.cat.items()}\n",
    "\n",
    "        self.meta = {}\n",
    "        splitfile = os.path.join(self.root, 'train_test_split', 'shuffled_{}_file_list.json'.format(split))\n",
    "        #from IPython import embed; embed()\n",
    "        filelist = json.load(open(splitfile, 'r'))\n",
    "        for item in self.cat:\n",
    "            self.meta[item] = []\n",
    "\n",
    "        for file in filelist:\n",
    "            _, category, uuid = file.split('/')\n",
    "            if category in self.cat.values():\n",
    "                self.meta[self.id2cat[category]].append((os.path.join(self.root, category, 'points', uuid+'.pts'),\n",
    "                                        os.path.join(self.root, category, 'points_label', uuid+'.seg')))\n",
    "\n",
    "        self.datapath = []\n",
    "        for item in self.cat:\n",
    "            for fn in self.meta[item]:\n",
    "                self.datapath.append((item, fn[0], fn[1]))\n",
    "\n",
    "        self.classes = dict(zip(sorted(self.cat), range(len(self.cat))))\n",
    "        print(self.classes)\n",
    "        with open('./misc/num_seg_classes.txt', 'r') as f:\n",
    "            for line in f:\n",
    "                ls = line.strip().split()\n",
    "                self.seg_classes[ls[0]] = int(ls[1])\n",
    "        self.num_seg_classes = self.seg_classes[list(self.cat.keys())[0]]\n",
    "        print(self.seg_classes, self.num_seg_classes)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        fn = self.datapath[index]\n",
    "        cls = self.classes[self.datapath[index][0]]\n",
    "        point_set = np.loadtxt(fn[1]).astype(np.float32)\n",
    "        seg = np.loadtxt(fn[2]).astype(np.int64)\n",
    "        #print(point_set.shape, seg.shape)\n",
    "\n",
    "        choice = np.random.choice(len(seg), self.npoints, replace=True)\n",
    "        #resample\n",
    "        point_set = point_set[choice, :]\n",
    "\n",
    "        point_set = point_set - np.expand_dims(np.mean(point_set, axis = 0), 0) # center\n",
    "        dist = np.max(np.sqrt(np.sum(point_set ** 2, axis = 1)),0)\n",
    "        point_set = point_set / dist #scale\n",
    "\n",
    "        if self.data_augmentation:\n",
    "            theta = np.random.uniform(0,np.pi*2)\n",
    "            rotation_matrix = np.array([[np.cos(theta), -np.sin(theta)],[np.sin(theta), np.cos(theta)]])\n",
    "            point_set[:,[0,2]] = point_set[:,[0,2]].dot(rotation_matrix) # random rotation\n",
    "            point_set += np.random.normal(0, 0.02, size=point_set.shape) # random jitter\n",
    "\n",
    "        seg = seg[choice]\n",
    "        point_set = torch.from_numpy(point_set)\n",
    "        seg = torch.from_numpy(seg)\n",
    "        cls = torch.from_numpy(np.array([cls]).astype(np.int64))\n",
    "\n",
    "        if self.classification:\n",
    "            return point_set, cls\n",
    "        else:\n",
    "            return point_set, seg\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.datapath)\n",
    "\n",
    "class ModelNetDataset(data.Dataset):\n",
    "    def __init__(self,\n",
    "                 root,\n",
    "                 npoints=2500,\n",
    "                 split='train',\n",
    "                 data_augmentation=False):\n",
    "        self.npoints = npoints\n",
    "        self.root = root\n",
    "        self.split = split\n",
    "        self.data_augmentation = data_augmentation\n",
    "        self.fns = []\n",
    "        with open(os.path.join(root, '{}.txt'.format(self.split)), 'r') as f:\n",
    "            for line in f:\n",
    "                self.fns.append(line.strip())\n",
    "\n",
    "        self.cat = {}\n",
    "        with open('./misc/modelnet_id.txt', 'r') as f:\n",
    "            for line in f:\n",
    "                ls = line.strip().split()\n",
    "                self.cat[ls[0]] = int(ls[1])\n",
    "\n",
    "        print(self.cat)\n",
    "        self.classes = list(self.cat.keys())\n",
    "    '''\n",
    "    def __getitem2__(self, index):\n",
    "      #impath, target = self.imlist[index]\n",
    "      myF = open(os.path.join(self.root, '{}.txt'.format(self.split)), 'r')\n",
    "      firstLine = myF.readline().strip()\n",
    "      if 'OFF' != firstLine[0:3]:\n",
    "          raise ValueError('Not a valid OFF header')\n",
    "      if len(firstLine) > 3:\n",
    "          n_verts, n_faces, n_edges = tuple([int(s) for s in firstLine[4:].split(' ')])\n",
    "      else:\n",
    "          n_verts, n_faces, n_edges = tuple([int(s) for s in myF.readline().strip().split(' ')])\n",
    "      verts = torch.tensor([[float(s) for s in myF.readline().strip().split(' ')] for i_vert in range(n_verts)])\n",
    "      #ipdb.set_trace(context=5)#\n",
    "      if verts.shape[0] > 0:\n",
    "        choice = np.random.choice(verts.shape[0], numpoints, replace=True)\n",
    "        point_set = verts[choice, :]\n",
    "      else:\n",
    "        point_set=verts \n",
    "      #faces = [[int(s) for s in myF.readline().strip().split(' ')][1:] for i_face in range(n_faces)]\n",
    "      return point_set, target '''\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.fns)\n",
    "\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        #ipdb.set_trace(context=5)#\n",
    "        fn = self.fns[index]\n",
    "        cls = self.cat[fn.split('/')[0]]\n",
    "        #ipdb.set_trace(context=5)#\n",
    "\n",
    "        '''\n",
    "        with open(os.path.join(self.root, fn), 'rb') as f:\n",
    "            plydata = PlyData.read(f)\n",
    "        pts = np.vstack([plydata['vertex']['x'], plydata['vertex']['y'], plydata['vertex']['z']]).T\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        with open(os.path.join(self.root, fn), 'r') as myF:\n",
    "            firstLine = myF.readline().strip()\n",
    "            #if 'OFF' != firstLine[0:3]:\n",
    "            #    raise ValueError('Not a valid OFF header')\n",
    "            if len(firstLine) > 3:\n",
    "                n_verts, n_faces, n_edges = tuple([int(s) for s in firstLine[4:].split(' ')])\n",
    "            else:\n",
    "                n_verts, n_faces, n_edges = tuple([int(s) for s in myF.readline().strip().split(' ')])\n",
    "            pts = np.array([[float(s) for s in myF.readline().strip().split(' ')] for i_vert in range(n_verts)])\n",
    "\n",
    "        \n",
    "        #ipdb.set_trace(context=5)#\n",
    "        choice = np.random.choice(len(pts), self.npoints, replace=True)\n",
    "        point_set = pts[choice, :]\n",
    "\n",
    "        point_set = point_set - np.expand_dims(np.mean(point_set, axis=0), 0)  # center\n",
    "        dist = np.max(np.sqrt(np.sum(point_set ** 2, axis=1)), 0)\n",
    "        point_set = point_set / dist  # scale\n",
    "\n",
    "        if self.data_augmentation:\n",
    "            theta = np.random.uniform(0, np.pi * 2)\n",
    "            rotation_matrix = np.array([[np.cos(theta), -np.sin(theta)], [np.sin(theta), np.cos(theta)]])\n",
    "            point_set[:, [0, 2]] = point_set[:, [0, 2]].dot(rotation_matrix)  # random rotation\n",
    "            point_set += np.random.normal(0, 0.02, size=point_set.shape)  # random jitter\n",
    "        #ipdb.set_trace(context=5)#\n",
    "        point_set = torch.from_numpy(point_set.astype(np.float32))\n",
    "        cls = torch.from_numpy(np.array([cls]).astype(np.int64))\n",
    "        return point_set, cls        \n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    dataset = sys.argv[1]\n",
    "    datapath = sys.argv[2]\n",
    "\n",
    "    if dataset == 'shapenet':\n",
    "        d = ShapeNetDataset(root = datapath, class_choice = ['Chair'])\n",
    "        print(len(d))\n",
    "        ps, seg = d[0]\n",
    "        print(ps.size(), ps.type(), seg.size(),seg.type())\n",
    "\n",
    "        d = ShapeNetDataset(root = datapath, classification = True)\n",
    "        print(len(d))\n",
    "        ps, cls = d[0]\n",
    "        print(ps.size(), ps.type(), cls.size(),cls.type())\n",
    "        # get_segmentation_classes(datapath)\n",
    "\n",
    "    if dataset == 'modelnet':\n",
    "        gen_modelnet_id(datapath)\n",
    "        d = ModelNetDataset(root=datapath)\n",
    "        print(len(d))\n",
    "        print(d[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ETPIH3i-uLHu",
    "outputId": "29adcab8-1c96-4564-ea2d-c19aaf830674"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'airplane': 0, 'bathtub': 1, 'bed': 2, 'bench': 3, 'bookshelf': 4, 'bottle': 5, 'bowl': 6, 'car': 7, 'chair': 8, 'cone': 9, 'cup': 10, 'curtain': 11, 'desk': 12, 'door': 13, 'dresser': 14, 'flower_pot': 15, 'glass_box': 16, 'guitar': 17, 'keyboard': 18, 'lamp': 19, 'laptop': 20, 'mantel': 21, 'monitor': 22, 'night_stand': 23, 'person': 24, 'piano': 25, 'plant': 26, 'radio': 27, 'range_hood': 28, 'sink': 29, 'sofa': 30, 'stairs': 31, 'stool': 32, 'table': 33, 'tent': 34, 'toilet': 35, 'tv_stand': 36, 'vase': 37, 'wardrobe': 38, 'xbox': 39}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class opt:\n",
    "  pass\n",
    "\n",
    "opt.batchSize=2\n",
    "opt.num_points=2500\n",
    "opt.workers=4\n",
    "opt.nepoch=10\n",
    "opt.outf='cls'\n",
    "opt.model=''\n",
    "\n",
    "opt.dataset='./ModelNet40'\n",
    "opt.dataset_type='modelnet40'\n",
    "'''\n",
    "opt.dataset='./shapenetcore_partanno_segmentation_benchmark_v0'\n",
    "opt.dataset_type='shapenet'\n",
    "'''\n",
    "dataset = ModelNetDataset(\n",
    "        root=opt.dataset,\n",
    "        npoints=opt.num_points)\n",
    "'''\n",
    "dataset = ShapeNetDataset(\n",
    "        root=opt.dataset,\n",
    "        classification=True,\n",
    "        npoints=opt.num_points)\n",
    "'''\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=opt.batchSize,\n",
    "    shuffle=True,\n",
    "    num_workers=int(opt.workers))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dHw0ZkCihyDA",
    "outputId": "8fd209ff-b377-4516-fda3-2dc9b6755e69"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2500, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader.dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IVCRUnxeugnX",
    "outputId": "b819ccf0-4cf9-43be-bc33-b3e10a39e4a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "> \u001b[0;32m<ipython-input-7-55f4cb6c8e5f>\u001b[0m(3)\u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m      1 \u001b[0;31m\u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      2 \u001b[0;31m  \u001b[0mipdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m----> 3 \u001b[0;31m  \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> data[0].shape\n",
      "torch.Size([2, 2500, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "PYDEV DEBUGGER WARNING:\n",
      "sys.settrace() should not be used when the debugger is being used.\n",
      "This may cause the debugger to stop working correctly.\n",
      "If this is needed, please check: \n",
      "http://pydev.blogspot.com/2007/06/why-cant-pydev-debugger-work-with.html\n",
      "to see how to restore the debug tracing back correctly.\n",
      "Call Location:\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/debugger.py\", line 974, in cmdloop\n",
      "    sys.settrace(None)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--KeyboardInterrupt--\n",
      "\n",
      "KeyboardInterrupt: Interrupted by user\n",
      "0\n",
      "None\n",
      "> \u001b[0;32m<ipython-input-7-55f4cb6c8e5f>\u001b[0m(2)\u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m      1 \u001b[0;31m\u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m----> 2 \u001b[0;31m  \u001b[0mipdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      3 \u001b[0;31m  \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> q\n"
     ]
    }
   ],
   "source": [
    "for i, data in enumerate(dataloader,0):\n",
    "  ipdb.set_trace(context=5)\n",
    "  print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "k1bghdq9XBRE",
    "outputId": "852e9196-8ef7-4990-ade4-ced4af0d3bde"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-87d180eb59ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'enumerate' object is not subscriptable"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-57-87d180eb59ce>\u001b[0m(1)\u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m----> 1 \u001b[0;31m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> q\n"
     ]
    }
   ],
   "source": [
    "str(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c87ah0KYoVw0",
    "outputId": "01159eaa-8832-4dc9-cdb4-8866cee35156"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vertx=np.array([0.,0.,1.,1.],dtype='float32')\n",
    "verty=np.array([0.,0.,1.,1.],dtype='float32')\n",
    "vertz=np.array([0.,0.,1.,1.],dtype='float32')\n",
    "pts = np.vstack([vertx, verty, vertz]).T\n",
    "pts.shape\n",
    "point_set = torch.from_numpy(pts.astype(np.float32))\n",
    "point_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LASejeuQVr1b",
    "outputId": "0243476b-f3e1-4061-8a74-0b3941c6f459"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n"
     ]
    }
   ],
   "source": [
    "%pdb on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Me65ztfUn3Gk",
    "outputId": "f24f1f23-eece-4515-ec32-477e92e7dc63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.opt'>\n",
      "Random Seed:  6925\n",
      "{'Airplane': 0, 'Bag': 1, 'Cap': 2, 'Car': 3, 'Chair': 4, 'Earphone': 5, 'Guitar': 6, 'Knife': 7, 'Lamp': 8, 'Laptop': 9, 'Motorbike': 10, 'Mug': 11, 'Pistol': 12, 'Rocket': 13, 'Skateboard': 14, 'Table': 15}\n",
      "{'Airplane': 4, 'Bag': 2, 'Cap': 2, 'Car': 4, 'Chair': 4, 'Earphone': 3, 'Guitar': 3, 'Knife': 2, 'Lamp': 4, 'Laptop': 2, 'Motorbike': 6, 'Mug': 2, 'Pistol': 3, 'Rocket': 3, 'Skateboard': 3, 'Table': 3} 4\n",
      "{'Airplane': 0, 'Bag': 1, 'Cap': 2, 'Car': 3, 'Chair': 4, 'Earphone': 5, 'Guitar': 6, 'Knife': 7, 'Lamp': 8, 'Laptop': 9, 'Motorbike': 10, 'Mug': 11, 'Pistol': 12, 'Rocket': 13, 'Skateboard': 14, 'Table': 15}\n",
      "{'Airplane': 4, 'Bag': 2, 'Cap': 2, 'Car': 4, 'Chair': 4, 'Earphone': 3, 'Guitar': 3, 'Knife': 2, 'Lamp': 4, 'Laptop': 2, 'Motorbike': 6, 'Mug': 2, 'Pistol': 3, 'Rocket': 3, 'Skateboard': 3, 'Table': 3} 4\n",
      "12137 2874\n",
      "classes 16\n",
      "debug1\n",
      "debug2\n",
      "--Return--\n",
      "None\n",
      "> \u001b[0;32m<ipython-input-10-b930440982ba>\u001b[0m(125)\u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    123 \u001b[0;31m\u001b[0;31m#ipdb.set_trace(context=5)#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    124 \u001b[0;31m\u001b[0mnum_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatchSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 125 \u001b[0;31m\u001b[0mipdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    126 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    127 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> c\n",
      "[0: 0/379] train loss: 3.026791 accuracy: 0.031250\n",
      "[0: 0/379] \u001b[94mtest\u001b[0m loss: 2.758200 accuracy: 0.031250\n",
      "[0: 1/379] train loss: 2.977104 accuracy: 0.125000\n",
      "[0: 2/379] train loss: 2.735710 accuracy: 0.250000\n",
      "[0: 3/379] train loss: 2.655262 accuracy: 0.312500\n",
      "[0: 4/379] train loss: 2.401272 accuracy: 0.375000\n",
      "[0: 5/379] train loss: 2.434696 accuracy: 0.343750\n",
      "[0: 6/379] train loss: 2.213037 accuracy: 0.406250\n",
      "[0: 7/379] train loss: 2.060914 accuracy: 0.500000\n",
      "[0: 8/379] train loss: 2.009845 accuracy: 0.562500\n",
      "[0: 9/379] train loss: 1.774076 accuracy: 0.625000\n",
      "[0: 10/379] train loss: 1.746015 accuracy: 0.562500\n",
      "[0: 10/379] \u001b[94mtest\u001b[0m loss: 2.565385 accuracy: 0.281250\n",
      "[0: 11/379] train loss: 1.706901 accuracy: 0.593750\n",
      "[0: 12/379] train loss: 1.746412 accuracy: 0.500000\n",
      "[0: 13/379] train loss: 1.778020 accuracy: 0.593750\n",
      "[0: 14/379] train loss: 1.683411 accuracy: 0.531250\n",
      "[0: 15/379] train loss: 1.466922 accuracy: 0.750000\n",
      "[0: 16/379] train loss: 1.197642 accuracy: 0.718750\n",
      "[0: 17/379] train loss: 1.161144 accuracy: 0.781250\n",
      "[0: 18/379] train loss: 1.563541 accuracy: 0.531250\n",
      "[0: 19/379] train loss: 1.212798 accuracy: 0.718750\n",
      "[0: 20/379] train loss: 1.359807 accuracy: 0.687500\n",
      "[0: 20/379] \u001b[94mtest\u001b[0m loss: 2.377964 accuracy: 0.218750\n",
      "[0: 21/379] train loss: 2.107821 accuracy: 0.437500\n",
      "[0: 22/379] train loss: 1.425118 accuracy: 0.687500\n",
      "[0: 23/379] train loss: 1.386078 accuracy: 0.656250\n",
      "[0: 24/379] train loss: 1.480900 accuracy: 0.718750\n",
      "[0: 25/379] train loss: 1.284129 accuracy: 0.656250\n",
      "[0: 26/379] train loss: 1.064964 accuracy: 0.875000\n",
      "[0: 27/379] train loss: 1.457403 accuracy: 0.593750\n",
      "[0: 28/379] train loss: 1.646407 accuracy: 0.531250\n",
      "[0: 29/379] train loss: 1.092131 accuracy: 0.781250\n",
      "[0: 30/379] train loss: 0.904537 accuracy: 0.750000\n",
      "[0: 30/379] \u001b[94mtest\u001b[0m loss: 2.217653 accuracy: 0.125000\n",
      "[0: 31/379] train loss: 1.103085 accuracy: 0.718750\n",
      "[0: 32/379] train loss: 0.949293 accuracy: 0.750000\n",
      "[0: 33/379] train loss: 1.308061 accuracy: 0.687500\n",
      "[0: 34/379] train loss: 1.270793 accuracy: 0.781250\n",
      "[0: 35/379] train loss: 1.039129 accuracy: 0.750000\n",
      "[0: 36/379] train loss: 1.024327 accuracy: 0.718750\n",
      "[0: 37/379] train loss: 1.192322 accuracy: 0.625000\n",
      "[0: 38/379] train loss: 1.243583 accuracy: 0.625000\n",
      "[0: 39/379] train loss: 1.751493 accuracy: 0.531250\n",
      "[0: 40/379] train loss: 1.033607 accuracy: 0.687500\n",
      "[0: 40/379] \u001b[94mtest\u001b[0m loss: 1.997077 accuracy: 0.343750\n",
      "[0: 41/379] train loss: 1.073349 accuracy: 0.718750\n",
      "[0: 42/379] train loss: 1.012701 accuracy: 0.718750\n",
      "[0: 43/379] train loss: 1.088678 accuracy: 0.625000\n",
      "[0: 44/379] train loss: 1.137872 accuracy: 0.718750\n",
      "[0: 45/379] train loss: 0.739309 accuracy: 0.812500\n",
      "[0: 46/379] train loss: 1.081207 accuracy: 0.750000\n",
      "[0: 47/379] train loss: 1.103987 accuracy: 0.656250\n",
      "[0: 48/379] train loss: 0.521783 accuracy: 0.906250\n",
      "[0: 49/379] train loss: 0.815843 accuracy: 0.812500\n",
      "[0: 50/379] train loss: 1.140040 accuracy: 0.687500\n",
      "[0: 50/379] \u001b[94mtest\u001b[0m loss: 1.809092 accuracy: 0.343750\n",
      "[0: 51/379] train loss: 1.144975 accuracy: 0.718750\n",
      "[0: 52/379] train loss: 1.073068 accuracy: 0.718750\n",
      "[0: 53/379] train loss: 0.756672 accuracy: 0.812500\n",
      "[0: 54/379] train loss: 0.682490 accuracy: 0.781250\n",
      "[0: 55/379] train loss: 0.944867 accuracy: 0.687500\n",
      "[0: 56/379] train loss: 1.143139 accuracy: 0.656250\n",
      "[0: 57/379] train loss: 1.257437 accuracy: 0.656250\n",
      "[0: 58/379] train loss: 0.866921 accuracy: 0.750000\n",
      "[0: 59/379] train loss: 0.996058 accuracy: 0.750000\n",
      "[0: 60/379] train loss: 0.649284 accuracy: 0.812500\n",
      "[0: 60/379] \u001b[94mtest\u001b[0m loss: 0.809086 accuracy: 0.750000\n",
      "[0: 61/379] train loss: 0.661971 accuracy: 0.812500\n",
      "[0: 62/379] train loss: 0.569386 accuracy: 0.843750\n",
      "[0: 63/379] train loss: 0.849911 accuracy: 0.687500\n",
      "[0: 64/379] train loss: 0.779978 accuracy: 0.718750\n",
      "[0: 65/379] train loss: 1.019683 accuracy: 0.656250\n",
      "[0: 66/379] train loss: 1.060343 accuracy: 0.656250\n",
      "[0: 67/379] train loss: 0.820488 accuracy: 0.750000\n",
      "[0: 68/379] train loss: 0.845660 accuracy: 0.781250\n",
      "[0: 69/379] train loss: 0.697324 accuracy: 0.843750\n",
      "[0: 70/379] train loss: 1.277477 accuracy: 0.656250\n",
      "[0: 70/379] \u001b[94mtest\u001b[0m loss: 1.035222 accuracy: 0.718750\n",
      "[0: 71/379] train loss: 0.856550 accuracy: 0.812500\n",
      "[0: 72/379] train loss: 1.396339 accuracy: 0.562500\n",
      "[0: 73/379] train loss: 0.942876 accuracy: 0.718750\n",
      "[0: 74/379] train loss: 0.959198 accuracy: 0.718750\n",
      "[0: 75/379] train loss: 0.873122 accuracy: 0.718750\n",
      "[0: 76/379] train loss: 1.565755 accuracy: 0.562500\n",
      "[0: 77/379] train loss: 0.716818 accuracy: 0.812500\n",
      "[0: 78/379] train loss: 1.086314 accuracy: 0.687500\n",
      "[0: 79/379] train loss: 0.808895 accuracy: 0.812500\n",
      "[0: 80/379] train loss: 1.091994 accuracy: 0.750000\n",
      "[0: 80/379] \u001b[94mtest\u001b[0m loss: 1.212338 accuracy: 0.625000\n",
      "[0: 81/379] train loss: 0.959291 accuracy: 0.812500\n",
      "[0: 82/379] train loss: 0.930522 accuracy: 0.843750\n",
      "[0: 83/379] train loss: 0.687379 accuracy: 0.812500\n",
      "[0: 84/379] train loss: 1.198961 accuracy: 0.625000\n",
      "[0: 85/379] train loss: 0.993992 accuracy: 0.718750\n",
      "[0: 86/379] train loss: 1.134137 accuracy: 0.718750\n",
      "[0: 87/379] train loss: 0.702804 accuracy: 0.781250\n",
      "[0: 88/379] train loss: 0.590218 accuracy: 0.875000\n",
      "[0: 89/379] train loss: 1.215799 accuracy: 0.625000\n",
      "[0: 90/379] train loss: 0.654400 accuracy: 0.812500\n",
      "[0: 90/379] \u001b[94mtest\u001b[0m loss: 1.001595 accuracy: 0.718750\n",
      "[0: 91/379] train loss: 0.765727 accuracy: 0.812500\n",
      "[0: 92/379] train loss: 0.888241 accuracy: 0.750000\n",
      "[0: 93/379] train loss: 0.881782 accuracy: 0.656250\n",
      "[0: 94/379] train loss: 0.765450 accuracy: 0.781250\n",
      "[0: 95/379] train loss: 1.068426 accuracy: 0.687500\n",
      "[0: 96/379] train loss: 0.768650 accuracy: 0.812500\n",
      "[0: 97/379] train loss: 0.753492 accuracy: 0.781250\n",
      "[0: 98/379] train loss: 0.907559 accuracy: 0.656250\n",
      "[0: 99/379] train loss: 0.876434 accuracy: 0.718750\n",
      "[0: 100/379] train loss: 0.742861 accuracy: 0.781250\n",
      "[0: 100/379] \u001b[94mtest\u001b[0m loss: 0.724153 accuracy: 0.843750\n",
      "[0: 101/379] train loss: 0.756348 accuracy: 0.875000\n",
      "[0: 102/379] train loss: 1.033597 accuracy: 0.750000\n",
      "[0: 103/379] train loss: 1.096199 accuracy: 0.781250\n",
      "[0: 104/379] train loss: 0.878539 accuracy: 0.781250\n",
      "[0: 105/379] train loss: 0.632497 accuracy: 0.781250\n",
      "[0: 106/379] train loss: 0.994756 accuracy: 0.687500\n",
      "[0: 107/379] train loss: 0.575767 accuracy: 0.843750\n",
      "[0: 108/379] train loss: 0.680215 accuracy: 0.843750\n",
      "[0: 109/379] train loss: 0.607043 accuracy: 0.875000\n",
      "[0: 110/379] train loss: 0.744664 accuracy: 0.812500\n",
      "[0: 110/379] \u001b[94mtest\u001b[0m loss: 0.990103 accuracy: 0.781250\n",
      "[0: 111/379] train loss: 0.658931 accuracy: 0.843750\n",
      "[0: 112/379] train loss: 0.536743 accuracy: 0.906250\n",
      "[0: 113/379] train loss: 1.114551 accuracy: 0.656250\n",
      "[0: 114/379] train loss: 0.996372 accuracy: 0.718750\n",
      "[0: 115/379] train loss: 1.191436 accuracy: 0.656250\n",
      "[0: 116/379] train loss: 0.691429 accuracy: 0.750000\n",
      "[0: 117/379] train loss: 0.538476 accuracy: 0.781250\n",
      "[0: 118/379] train loss: 0.846917 accuracy: 0.812500\n",
      "[0: 119/379] train loss: 0.782399 accuracy: 0.750000\n",
      "[0: 120/379] train loss: 0.656991 accuracy: 0.843750\n",
      "[0: 120/379] \u001b[94mtest\u001b[0m loss: 0.742331 accuracy: 0.781250\n",
      "[0: 121/379] train loss: 0.683560 accuracy: 0.781250\n",
      "[0: 122/379] train loss: 0.342053 accuracy: 0.906250\n",
      "[0: 123/379] train loss: 0.576437 accuracy: 0.968750\n",
      "[0: 124/379] train loss: 0.679885 accuracy: 0.812500\n",
      "[0: 125/379] train loss: 0.488158 accuracy: 0.812500\n",
      "[0: 126/379] train loss: 1.179819 accuracy: 0.718750\n",
      "[0: 127/379] train loss: 0.681378 accuracy: 0.843750\n",
      "[0: 128/379] train loss: 0.651257 accuracy: 0.781250\n",
      "[0: 129/379] train loss: 0.792504 accuracy: 0.812500\n",
      "[0: 130/379] train loss: 0.663422 accuracy: 0.843750\n",
      "[0: 130/379] \u001b[94mtest\u001b[0m loss: 1.150202 accuracy: 0.718750\n",
      "[0: 131/379] train loss: 0.514688 accuracy: 0.843750\n",
      "[0: 132/379] train loss: 0.776069 accuracy: 0.781250\n",
      "[0: 133/379] train loss: 0.554207 accuracy: 0.843750\n",
      "[0: 134/379] train loss: 0.751197 accuracy: 0.875000\n",
      "[0: 135/379] train loss: 0.764938 accuracy: 0.812500\n",
      "[0: 136/379] train loss: 0.742040 accuracy: 0.812500\n",
      "[0: 137/379] train loss: 0.865557 accuracy: 0.812500\n",
      "[0: 138/379] train loss: 0.646018 accuracy: 0.875000\n",
      "[0: 139/379] train loss: 0.487097 accuracy: 0.937500\n",
      "[0: 140/379] train loss: 0.754110 accuracy: 0.781250\n",
      "[0: 140/379] \u001b[94mtest\u001b[0m loss: 0.794509 accuracy: 0.750000\n",
      "[0: 141/379] train loss: 0.854657 accuracy: 0.750000\n",
      "[0: 142/379] train loss: 0.990335 accuracy: 0.750000\n",
      "[0: 143/379] train loss: 0.475151 accuracy: 0.843750\n",
      "[0: 144/379] train loss: 0.638281 accuracy: 0.843750\n",
      "[0: 145/379] train loss: 0.726462 accuracy: 0.812500\n",
      "[0: 146/379] train loss: 0.614084 accuracy: 0.812500\n",
      "[0: 147/379] train loss: 0.473889 accuracy: 0.875000\n",
      "[0: 148/379] train loss: 0.492673 accuracy: 0.875000\n",
      "[0: 149/379] train loss: 0.374654 accuracy: 0.906250\n",
      "[0: 150/379] train loss: 0.628441 accuracy: 0.875000\n",
      "[0: 150/379] \u001b[94mtest\u001b[0m loss: 0.400828 accuracy: 0.875000\n",
      "[0: 151/379] train loss: 0.636937 accuracy: 0.843750\n",
      "[0: 152/379] train loss: 0.662985 accuracy: 0.812500\n",
      "[0: 153/379] train loss: 0.852186 accuracy: 0.812500\n",
      "[0: 154/379] train loss: 0.592455 accuracy: 0.812500\n",
      "[0: 155/379] train loss: 0.629144 accuracy: 0.875000\n",
      "[0: 156/379] train loss: 0.465048 accuracy: 0.843750\n",
      "[0: 157/379] train loss: 0.619413 accuracy: 0.875000\n",
      "[0: 158/379] train loss: 0.608140 accuracy: 0.875000\n",
      "[0: 159/379] train loss: 0.501234 accuracy: 0.843750\n",
      "[0: 160/379] train loss: 0.467371 accuracy: 0.875000\n",
      "[0: 160/379] \u001b[94mtest\u001b[0m loss: 0.961078 accuracy: 0.781250\n",
      "[0: 161/379] train loss: 0.609831 accuracy: 0.875000\n",
      "[0: 162/379] train loss: 0.653882 accuracy: 0.781250\n",
      "[0: 163/379] train loss: 0.512886 accuracy: 0.906250\n",
      "[0: 164/379] train loss: 1.193378 accuracy: 0.750000\n",
      "[0: 165/379] train loss: 0.456794 accuracy: 0.906250\n",
      "[0: 166/379] train loss: 0.750354 accuracy: 0.812500\n",
      "[0: 167/379] train loss: 1.072389 accuracy: 0.687500\n",
      "[0: 168/379] train loss: 0.285744 accuracy: 0.937500\n",
      "[0: 169/379] train loss: 0.622129 accuracy: 0.875000\n",
      "[0: 170/379] train loss: 0.647578 accuracy: 0.843750\n",
      "[0: 170/379] \u001b[94mtest\u001b[0m loss: 0.509866 accuracy: 0.843750\n",
      "[0: 171/379] train loss: 0.507162 accuracy: 0.843750\n",
      "[0: 172/379] train loss: 0.958210 accuracy: 0.750000\n",
      "[0: 173/379] train loss: 0.697722 accuracy: 0.750000\n",
      "[0: 174/379] train loss: 1.028447 accuracy: 0.687500\n",
      "[0: 175/379] train loss: 0.664314 accuracy: 0.843750\n",
      "[0: 176/379] train loss: 0.429757 accuracy: 0.906250\n",
      "[0: 177/379] train loss: 0.811615 accuracy: 0.812500\n",
      "[0: 178/379] train loss: 0.737355 accuracy: 0.781250\n",
      "[0: 179/379] train loss: 1.101764 accuracy: 0.718750\n",
      "[0: 180/379] train loss: 0.591780 accuracy: 0.843750\n",
      "[0: 180/379] \u001b[94mtest\u001b[0m loss: 0.714163 accuracy: 0.812500\n",
      "[0: 181/379] train loss: 0.742608 accuracy: 0.843750\n",
      "[0: 182/379] train loss: 0.754333 accuracy: 0.812500\n",
      "[0: 183/379] train loss: 0.656405 accuracy: 0.750000\n",
      "[0: 184/379] train loss: 0.727434 accuracy: 0.750000\n",
      "[0: 185/379] train loss: 0.429299 accuracy: 0.906250\n",
      "[0: 186/379] train loss: 0.306902 accuracy: 0.937500\n",
      "[0: 187/379] train loss: 1.031039 accuracy: 0.718750\n",
      "[0: 188/379] train loss: 1.071083 accuracy: 0.718750\n",
      "[0: 189/379] train loss: 0.443154 accuracy: 0.843750\n",
      "[0: 190/379] train loss: 0.857418 accuracy: 0.750000\n",
      "[0: 190/379] \u001b[94mtest\u001b[0m loss: 0.422337 accuracy: 0.875000\n",
      "[0: 191/379] train loss: 0.692517 accuracy: 0.875000\n",
      "[0: 192/379] train loss: 1.120734 accuracy: 0.656250\n",
      "[0: 193/379] train loss: 0.545916 accuracy: 0.875000\n",
      "[0: 194/379] train loss: 0.545198 accuracy: 0.875000\n",
      "[0: 195/379] train loss: 0.527677 accuracy: 0.843750\n",
      "[0: 196/379] train loss: 0.726428 accuracy: 0.843750\n",
      "[0: 197/379] train loss: 0.445886 accuracy: 0.875000\n",
      "[0: 198/379] train loss: 0.552763 accuracy: 0.875000\n",
      "[0: 199/379] train loss: 0.734556 accuracy: 0.812500\n",
      "[0: 200/379] train loss: 0.636931 accuracy: 0.906250\n",
      "[0: 200/379] \u001b[94mtest\u001b[0m loss: 0.915170 accuracy: 0.750000\n",
      "[0: 201/379] train loss: 0.519397 accuracy: 0.875000\n",
      "[0: 202/379] train loss: 0.521024 accuracy: 0.875000\n",
      "[0: 203/379] train loss: 0.652675 accuracy: 0.781250\n",
      "[0: 204/379] train loss: 0.604874 accuracy: 0.781250\n",
      "[0: 205/379] train loss: 0.759683 accuracy: 0.812500\n",
      "[0: 206/379] train loss: 0.960532 accuracy: 0.656250\n",
      "[0: 207/379] train loss: 0.456123 accuracy: 0.843750\n",
      "[0: 208/379] train loss: 0.727269 accuracy: 0.812500\n",
      "[0: 209/379] train loss: 0.649028 accuracy: 0.843750\n",
      "[0: 210/379] train loss: 0.529412 accuracy: 0.843750\n",
      "[0: 210/379] \u001b[94mtest\u001b[0m loss: 0.610151 accuracy: 0.843750\n",
      "[0: 211/379] train loss: 0.389169 accuracy: 0.906250\n",
      "[0: 212/379] train loss: 0.571000 accuracy: 0.812500\n",
      "[0: 213/379] train loss: 1.088409 accuracy: 0.750000\n",
      "[0: 214/379] train loss: 0.385586 accuracy: 0.937500\n",
      "[0: 215/379] train loss: 0.525670 accuracy: 0.812500\n",
      "[0: 216/379] train loss: 0.581903 accuracy: 0.781250\n",
      "[0: 217/379] train loss: 0.553721 accuracy: 0.843750\n",
      "[0: 218/379] train loss: 1.069787 accuracy: 0.781250\n",
      "[0: 219/379] train loss: 0.791166 accuracy: 0.750000\n",
      "[0: 220/379] train loss: 0.780275 accuracy: 0.750000\n",
      "[0: 220/379] \u001b[94mtest\u001b[0m loss: 0.680889 accuracy: 0.750000\n",
      "[0: 221/379] train loss: 0.717683 accuracy: 0.812500\n",
      "[0: 222/379] train loss: 0.656840 accuracy: 0.781250\n",
      "[0: 223/379] train loss: 0.341089 accuracy: 0.906250\n",
      "[0: 224/379] train loss: 0.846966 accuracy: 0.812500\n",
      "[0: 225/379] train loss: 0.397667 accuracy: 0.906250\n",
      "[0: 226/379] train loss: 0.818375 accuracy: 0.750000\n",
      "[0: 227/379] train loss: 0.638298 accuracy: 0.843750\n",
      "[0: 228/379] train loss: 0.326755 accuracy: 0.937500\n",
      "[0: 229/379] train loss: 0.955599 accuracy: 0.718750\n",
      "[0: 230/379] train loss: 0.268759 accuracy: 0.937500\n",
      "[0: 230/379] \u001b[94mtest\u001b[0m loss: 1.195558 accuracy: 0.687500\n",
      "[0: 231/379] train loss: 0.373356 accuracy: 0.906250\n",
      "[0: 232/379] train loss: 0.581690 accuracy: 0.843750\n",
      "[0: 233/379] train loss: 0.669211 accuracy: 0.812500\n",
      "[0: 234/379] train loss: 0.685147 accuracy: 0.812500\n",
      "[0: 235/379] train loss: 0.834398 accuracy: 0.781250\n",
      "[0: 236/379] train loss: 1.051971 accuracy: 0.687500\n",
      "[0: 237/379] train loss: 0.623369 accuracy: 0.875000\n",
      "[0: 238/379] train loss: 1.198288 accuracy: 0.687500\n",
      "[0: 239/379] train loss: 0.516300 accuracy: 0.843750\n",
      "[0: 240/379] train loss: 0.580936 accuracy: 0.812500\n",
      "[0: 240/379] \u001b[94mtest\u001b[0m loss: 0.635168 accuracy: 0.812500\n",
      "[0: 241/379] train loss: 0.851540 accuracy: 0.781250\n",
      "[0: 242/379] train loss: 0.544769 accuracy: 0.875000\n",
      "[0: 243/379] train loss: 0.351921 accuracy: 0.906250\n",
      "[0: 244/379] train loss: 0.561063 accuracy: 0.875000\n",
      "[0: 245/379] train loss: 0.733008 accuracy: 0.812500\n",
      "[0: 246/379] train loss: 0.691087 accuracy: 0.843750\n",
      "[0: 247/379] train loss: 0.821638 accuracy: 0.781250\n",
      "[0: 248/379] train loss: 0.458077 accuracy: 0.875000\n",
      "[0: 249/379] train loss: 0.777030 accuracy: 0.781250\n",
      "[0: 250/379] train loss: 0.635270 accuracy: 0.812500\n",
      "[0: 250/379] \u001b[94mtest\u001b[0m loss: 0.258795 accuracy: 0.937500\n",
      "[0: 251/379] train loss: 0.625646 accuracy: 0.843750\n",
      "[0: 252/379] train loss: 0.754743 accuracy: 0.750000\n",
      "[0: 253/379] train loss: 0.449814 accuracy: 0.875000\n",
      "[0: 254/379] train loss: 0.975566 accuracy: 0.781250\n",
      "[0: 255/379] train loss: 0.596841 accuracy: 0.906250\n",
      "[0: 256/379] train loss: 0.551594 accuracy: 0.843750\n",
      "[0: 257/379] train loss: 0.483387 accuracy: 0.843750\n",
      "[0: 258/379] train loss: 0.540650 accuracy: 0.843750\n",
      "[0: 259/379] train loss: 0.541469 accuracy: 0.843750\n",
      "[0: 260/379] train loss: 0.901924 accuracy: 0.750000\n",
      "[0: 260/379] \u001b[94mtest\u001b[0m loss: 0.566877 accuracy: 0.781250\n",
      "[0: 261/379] train loss: 0.340345 accuracy: 0.875000\n",
      "[0: 262/379] train loss: 0.419638 accuracy: 0.906250\n",
      "[0: 263/379] train loss: 0.578676 accuracy: 0.812500\n",
      "[0: 264/379] train loss: 0.405491 accuracy: 0.875000\n",
      "[0: 265/379] train loss: 0.336443 accuracy: 0.906250\n",
      "[0: 266/379] train loss: 0.596515 accuracy: 0.875000\n",
      "[0: 267/379] train loss: 0.395384 accuracy: 0.906250\n",
      "[0: 268/379] train loss: 0.364470 accuracy: 0.843750\n",
      "[0: 269/379] train loss: 0.490097 accuracy: 0.843750\n",
      "[0: 270/379] train loss: 0.730305 accuracy: 0.781250\n",
      "[0: 270/379] \u001b[94mtest\u001b[0m loss: 0.487521 accuracy: 0.875000\n",
      "[0: 271/379] train loss: 0.444986 accuracy: 0.843750\n",
      "[0: 272/379] train loss: 0.834577 accuracy: 0.750000\n",
      "[0: 273/379] train loss: 0.510422 accuracy: 0.875000\n",
      "[0: 274/379] train loss: 0.372362 accuracy: 0.906250\n",
      "[0: 275/379] train loss: 0.553453 accuracy: 0.875000\n",
      "[0: 276/379] train loss: 0.558439 accuracy: 0.843750\n",
      "[0: 277/379] train loss: 0.407491 accuracy: 0.875000\n",
      "[0: 278/379] train loss: 0.707244 accuracy: 0.687500\n",
      "[0: 279/379] train loss: 0.469128 accuracy: 0.812500\n",
      "[0: 280/379] train loss: 0.512189 accuracy: 0.812500\n",
      "[0: 280/379] \u001b[94mtest\u001b[0m loss: 0.158959 accuracy: 0.968750\n",
      "[0: 281/379] train loss: 0.561625 accuracy: 0.781250\n",
      "[0: 282/379] train loss: 0.557155 accuracy: 0.906250\n",
      "[0: 283/379] train loss: 0.462001 accuracy: 0.906250\n",
      "[0: 284/379] train loss: 0.576399 accuracy: 0.875000\n",
      "[0: 285/379] train loss: 0.609568 accuracy: 0.843750\n",
      "[0: 286/379] train loss: 0.529765 accuracy: 0.906250\n",
      "[0: 287/379] train loss: 0.286829 accuracy: 0.937500\n",
      "[0: 288/379] train loss: 0.773215 accuracy: 0.843750\n",
      "[0: 289/379] train loss: 0.960120 accuracy: 0.718750\n",
      "[0: 290/379] train loss: 0.503250 accuracy: 0.875000\n",
      "[0: 290/379] \u001b[94mtest\u001b[0m loss: 0.152979 accuracy: 0.968750\n",
      "[0: 291/379] train loss: 0.510325 accuracy: 0.843750\n",
      "[0: 292/379] train loss: 0.676053 accuracy: 0.843750\n",
      "[0: 293/379] train loss: 0.961549 accuracy: 0.656250\n",
      "[0: 294/379] train loss: 0.734349 accuracy: 0.812500\n",
      "[0: 295/379] train loss: 0.542919 accuracy: 0.843750\n",
      "[0: 296/379] train loss: 0.916308 accuracy: 0.812500\n",
      "[0: 297/379] train loss: 0.870684 accuracy: 0.750000\n",
      "[0: 298/379] train loss: 0.374096 accuracy: 0.875000\n",
      "[0: 299/379] train loss: 0.680771 accuracy: 0.781250\n",
      "[0: 300/379] train loss: 0.498221 accuracy: 0.875000\n",
      "[0: 300/379] \u001b[94mtest\u001b[0m loss: 0.389935 accuracy: 0.875000\n",
      "[0: 301/379] train loss: 0.428246 accuracy: 0.875000\n",
      "[0: 302/379] train loss: 0.409215 accuracy: 0.843750\n",
      "[0: 303/379] train loss: 0.493861 accuracy: 0.843750\n",
      "[0: 304/379] train loss: 0.868564 accuracy: 0.718750\n",
      "[0: 305/379] train loss: 0.578098 accuracy: 0.843750\n",
      "[0: 306/379] train loss: 0.397835 accuracy: 0.843750\n",
      "[0: 307/379] train loss: 0.337220 accuracy: 0.937500\n",
      "[0: 308/379] train loss: 0.456346 accuracy: 0.812500\n",
      "[0: 309/379] train loss: 0.822335 accuracy: 0.812500\n",
      "[0: 310/379] train loss: 0.262283 accuracy: 0.937500\n",
      "[0: 310/379] \u001b[94mtest\u001b[0m loss: 0.414561 accuracy: 0.875000\n",
      "[0: 311/379] train loss: 0.492360 accuracy: 0.875000\n",
      "[0: 312/379] train loss: 0.612761 accuracy: 0.843750\n",
      "[0: 313/379] train loss: 0.507150 accuracy: 0.781250\n",
      "[0: 314/379] train loss: 0.669132 accuracy: 0.812500\n",
      "[0: 315/379] train loss: 0.568763 accuracy: 0.781250\n",
      "[0: 316/379] train loss: 0.256565 accuracy: 0.843750\n",
      "[0: 317/379] train loss: 0.454613 accuracy: 0.812500\n",
      "[0: 318/379] train loss: 0.642647 accuracy: 0.750000\n",
      "[0: 319/379] train loss: 0.416235 accuracy: 0.875000\n",
      "[0: 320/379] train loss: 0.672967 accuracy: 0.843750\n",
      "[0: 320/379] \u001b[94mtest\u001b[0m loss: 0.473232 accuracy: 0.812500\n",
      "[0: 321/379] train loss: 0.292306 accuracy: 0.906250\n",
      "[0: 322/379] train loss: 0.295362 accuracy: 0.875000\n",
      "[0: 323/379] train loss: 0.467658 accuracy: 0.843750\n",
      "[0: 324/379] train loss: 0.693541 accuracy: 0.875000\n",
      "[0: 325/379] train loss: 0.596323 accuracy: 0.812500\n",
      "[0: 326/379] train loss: 0.583710 accuracy: 0.781250\n",
      "[0: 327/379] train loss: 0.799497 accuracy: 0.750000\n",
      "[0: 328/379] train loss: 0.593941 accuracy: 0.906250\n",
      "[0: 329/379] train loss: 0.464580 accuracy: 0.781250\n",
      "[0: 330/379] train loss: 0.324853 accuracy: 0.906250\n",
      "[0: 330/379] \u001b[94mtest\u001b[0m loss: 0.339712 accuracy: 0.906250\n",
      "[0: 331/379] train loss: 0.359049 accuracy: 0.906250\n",
      "[0: 332/379] train loss: 0.500222 accuracy: 0.875000\n",
      "[0: 333/379] train loss: 0.344523 accuracy: 0.875000\n",
      "[0: 334/379] train loss: 0.307048 accuracy: 0.906250\n",
      "[0: 335/379] train loss: 0.775185 accuracy: 0.781250\n",
      "[0: 336/379] train loss: 0.649043 accuracy: 0.843750\n",
      "[0: 337/379] train loss: 0.684636 accuracy: 0.750000\n",
      "[0: 338/379] train loss: 0.606654 accuracy: 0.812500\n",
      "[0: 339/379] train loss: 0.434258 accuracy: 0.781250\n",
      "[0: 340/379] train loss: 0.633223 accuracy: 0.781250\n",
      "[0: 340/379] \u001b[94mtest\u001b[0m loss: 0.537319 accuracy: 0.906250\n",
      "[0: 341/379] train loss: 0.434227 accuracy: 0.875000\n",
      "[0: 342/379] train loss: 0.316430 accuracy: 0.906250\n",
      "[0: 343/379] train loss: 0.871964 accuracy: 0.812500\n",
      "[0: 344/379] train loss: 0.957996 accuracy: 0.687500\n",
      "[0: 345/379] train loss: 0.447282 accuracy: 0.875000\n",
      "[0: 346/379] train loss: 0.470478 accuracy: 0.812500\n",
      "[0: 347/379] train loss: 0.479290 accuracy: 0.906250\n",
      "[0: 348/379] train loss: 0.564623 accuracy: 0.843750\n",
      "[0: 349/379] train loss: 0.544737 accuracy: 0.812500\n",
      "[0: 350/379] train loss: 0.446188 accuracy: 0.875000\n",
      "[0: 350/379] \u001b[94mtest\u001b[0m loss: 0.980455 accuracy: 0.656250\n",
      "[0: 351/379] train loss: 0.352295 accuracy: 0.906250\n",
      "[0: 352/379] train loss: 0.412419 accuracy: 0.875000\n",
      "[0: 353/379] train loss: 0.379929 accuracy: 0.875000\n",
      "[0: 354/379] train loss: 0.729603 accuracy: 0.812500\n",
      "[0: 355/379] train loss: 0.429206 accuracy: 0.906250\n",
      "[0: 356/379] train loss: 0.515691 accuracy: 0.812500\n",
      "[0: 357/379] train loss: 0.488807 accuracy: 0.875000\n",
      "[0: 358/379] train loss: 0.642641 accuracy: 0.812500\n",
      "[0: 359/379] train loss: 0.364295 accuracy: 0.906250\n",
      "[0: 360/379] train loss: 0.404848 accuracy: 0.875000\n",
      "[0: 360/379] \u001b[94mtest\u001b[0m loss: 0.295008 accuracy: 0.875000\n",
      "[0: 361/379] train loss: 0.339583 accuracy: 0.937500\n",
      "[0: 362/379] train loss: 0.368250 accuracy: 0.843750\n",
      "[0: 363/379] train loss: 0.470879 accuracy: 0.875000\n",
      "[0: 364/379] train loss: 0.184520 accuracy: 0.968750\n",
      "[0: 365/379] train loss: 0.274770 accuracy: 0.875000\n",
      "[0: 366/379] train loss: 0.697368 accuracy: 0.843750\n",
      "[0: 367/379] train loss: 0.272718 accuracy: 0.937500\n",
      "[0: 368/379] train loss: 0.341260 accuracy: 0.937500\n",
      "[0: 369/379] train loss: 0.216653 accuracy: 1.000000\n",
      "[0: 370/379] train loss: 0.829255 accuracy: 0.843750\n",
      "[0: 370/379] \u001b[94mtest\u001b[0m loss: 0.593568 accuracy: 0.812500\n",
      "[0: 371/379] train loss: 0.252603 accuracy: 0.937500\n",
      "[0: 372/379] train loss: 0.584191 accuracy: 0.812500\n",
      "[0: 373/379] train loss: 0.636886 accuracy: 0.812500\n",
      "[0: 374/379] train loss: 0.742234 accuracy: 0.781250\n",
      "[0: 375/379] train loss: 0.624490 accuracy: 0.906250\n",
      "[0: 376/379] train loss: 0.608045 accuracy: 0.843750\n",
      "[0: 377/379] train loss: 0.439200 accuracy: 0.875000\n",
      "[0: 378/379] train loss: 0.462651 accuracy: 0.843750\n",
      "[0: 379/379] train loss: 0.867260 accuracy: 0.218750\n",
      "[1: 0/379] train loss: 0.481959 accuracy: 0.843750\n",
      "[1: 0/379] \u001b[94mtest\u001b[0m loss: 0.515823 accuracy: 0.781250\n",
      "[1: 1/379] train loss: 0.706894 accuracy: 0.812500\n",
      "[1: 2/379] train loss: 0.556026 accuracy: 0.875000\n",
      "[1: 3/379] train loss: 0.512302 accuracy: 0.843750\n",
      "[1: 4/379] train loss: 0.198056 accuracy: 1.000000\n",
      "[1: 5/379] train loss: 0.656288 accuracy: 0.750000\n",
      "[1: 6/379] train loss: 0.602057 accuracy: 0.781250\n",
      "[1: 7/379] train loss: 0.489007 accuracy: 0.843750\n",
      "[1: 8/379] train loss: 0.606865 accuracy: 0.812500\n",
      "[1: 9/379] train loss: 0.685048 accuracy: 0.843750\n",
      "[1: 10/379] train loss: 0.381244 accuracy: 0.937500\n",
      "[1: 10/379] \u001b[94mtest\u001b[0m loss: 0.829096 accuracy: 0.718750\n",
      "[1: 11/379] train loss: 0.449462 accuracy: 0.937500\n",
      "[1: 12/379] train loss: 0.701957 accuracy: 0.875000\n",
      "[1: 13/379] train loss: 0.508497 accuracy: 0.875000\n",
      "[1: 14/379] train loss: 0.486449 accuracy: 0.875000\n",
      "[1: 15/379] train loss: 0.273903 accuracy: 0.906250\n",
      "[1: 16/379] train loss: 0.460473 accuracy: 0.843750\n",
      "[1: 17/379] train loss: 0.758659 accuracy: 0.812500\n",
      "[1: 18/379] train loss: 0.409023 accuracy: 0.906250\n",
      "[1: 19/379] train loss: 0.949610 accuracy: 0.750000\n",
      "[1: 20/379] train loss: 0.328266 accuracy: 0.937500\n",
      "[1: 20/379] \u001b[94mtest\u001b[0m loss: 0.461129 accuracy: 0.781250\n",
      "[1: 21/379] train loss: 0.809201 accuracy: 0.750000\n",
      "[1: 22/379] train loss: 0.442010 accuracy: 0.906250\n",
      "[1: 23/379] train loss: 0.314847 accuracy: 0.968750\n",
      "[1: 24/379] train loss: 0.453047 accuracy: 0.843750\n",
      "[1: 25/379] train loss: 0.313903 accuracy: 0.937500\n",
      "[1: 26/379] train loss: 0.355465 accuracy: 0.906250\n",
      "[1: 27/379] train loss: 0.495858 accuracy: 0.812500\n",
      "[1: 28/379] train loss: 0.456160 accuracy: 0.937500\n",
      "[1: 29/379] train loss: 0.403645 accuracy: 0.937500\n",
      "[1: 30/379] train loss: 0.628890 accuracy: 0.843750\n",
      "[1: 30/379] \u001b[94mtest\u001b[0m loss: 0.587787 accuracy: 0.843750\n",
      "[1: 31/379] train loss: 0.277832 accuracy: 0.968750\n",
      "[1: 32/379] train loss: 0.310755 accuracy: 0.875000\n",
      "[1: 33/379] train loss: 0.386187 accuracy: 0.906250\n",
      "[1: 34/379] train loss: 0.343241 accuracy: 0.906250\n",
      "[1: 35/379] train loss: 0.421648 accuracy: 0.937500\n",
      "[1: 36/379] train loss: 0.448938 accuracy: 0.906250\n",
      "[1: 37/379] train loss: 0.377745 accuracy: 0.875000\n",
      "[1: 38/379] train loss: 0.806013 accuracy: 0.718750\n",
      "[1: 39/379] train loss: 0.392728 accuracy: 0.843750\n",
      "[1: 40/379] train loss: 0.473445 accuracy: 0.812500\n",
      "[1: 40/379] \u001b[94mtest\u001b[0m loss: 0.456021 accuracy: 0.781250\n",
      "[1: 41/379] train loss: 0.630381 accuracy: 0.812500\n",
      "[1: 42/379] train loss: 0.432611 accuracy: 0.906250\n",
      "[1: 43/379] train loss: 0.390312 accuracy: 0.875000\n",
      "[1: 44/379] train loss: 0.340409 accuracy: 0.906250\n",
      "[1: 45/379] train loss: 0.554741 accuracy: 0.906250\n",
      "[1: 46/379] train loss: 0.507128 accuracy: 0.875000\n",
      "[1: 47/379] train loss: 0.297475 accuracy: 0.937500\n",
      "[1: 48/379] train loss: 0.250015 accuracy: 0.937500\n",
      "[1: 49/379] train loss: 0.426839 accuracy: 0.937500\n",
      "[1: 50/379] train loss: 0.589299 accuracy: 0.843750\n",
      "[1: 50/379] \u001b[94mtest\u001b[0m loss: 0.353573 accuracy: 0.937500\n",
      "[1: 51/379] train loss: 0.610935 accuracy: 0.843750\n",
      "[1: 52/379] train loss: 0.618659 accuracy: 0.781250\n",
      "[1: 53/379] train loss: 0.403303 accuracy: 0.906250\n",
      "[1: 54/379] train loss: 0.322172 accuracy: 0.906250\n",
      "[1: 55/379] train loss: 0.313522 accuracy: 0.906250\n",
      "[1: 56/379] train loss: 0.635145 accuracy: 0.875000\n",
      "[1: 57/379] train loss: 0.206711 accuracy: 0.968750\n",
      "[1: 58/379] train loss: 0.365716 accuracy: 0.875000\n",
      "[1: 59/379] train loss: 0.303485 accuracy: 0.906250\n",
      "[1: 60/379] train loss: 0.488417 accuracy: 0.875000\n",
      "[1: 60/379] \u001b[94mtest\u001b[0m loss: 0.679847 accuracy: 0.843750\n",
      "[1: 61/379] train loss: 0.512191 accuracy: 0.843750\n",
      "[1: 62/379] train loss: 0.339035 accuracy: 0.906250\n",
      "[1: 63/379] train loss: 0.313357 accuracy: 0.875000\n",
      "[1: 64/379] train loss: 0.223572 accuracy: 0.937500\n",
      "[1: 65/379] train loss: 0.378363 accuracy: 0.875000\n",
      "[1: 66/379] train loss: 0.465785 accuracy: 0.843750\n",
      "[1: 67/379] train loss: 0.312305 accuracy: 0.906250\n",
      "[1: 68/379] train loss: 0.272683 accuracy: 0.968750\n",
      "[1: 69/379] train loss: 0.242298 accuracy: 0.968750\n",
      "[1: 70/379] train loss: 0.443282 accuracy: 0.875000\n",
      "[1: 70/379] \u001b[94mtest\u001b[0m loss: 0.521510 accuracy: 0.875000\n",
      "[1: 71/379] train loss: 0.233150 accuracy: 0.906250\n",
      "[1: 72/379] train loss: 0.397529 accuracy: 0.937500\n",
      "[1: 73/379] train loss: 0.693127 accuracy: 0.875000\n",
      "[1: 74/379] train loss: 0.639073 accuracy: 0.843750\n",
      "[1: 75/379] train loss: 0.300802 accuracy: 0.937500\n",
      "[1: 76/379] train loss: 0.283858 accuracy: 0.906250\n",
      "[1: 77/379] train loss: 0.146695 accuracy: 0.968750\n",
      "[1: 78/379] train loss: 0.833647 accuracy: 0.750000\n",
      "[1: 79/379] train loss: 0.254932 accuracy: 0.937500\n",
      "[1: 80/379] train loss: 0.515794 accuracy: 0.843750\n",
      "[1: 80/379] \u001b[94mtest\u001b[0m loss: 0.413347 accuracy: 0.906250\n",
      "[1: 81/379] train loss: 0.363378 accuracy: 0.843750\n",
      "[1: 82/379] train loss: 0.360903 accuracy: 0.875000\n",
      "[1: 83/379] train loss: 0.509518 accuracy: 0.875000\n",
      "[1: 84/379] train loss: 0.633516 accuracy: 0.812500\n",
      "[1: 85/379] train loss: 0.205127 accuracy: 0.968750\n",
      "[1: 86/379] train loss: 1.069439 accuracy: 0.718750\n",
      "[1: 87/379] train loss: 0.317378 accuracy: 0.906250\n",
      "[1: 88/379] train loss: 0.889745 accuracy: 0.781250\n",
      "[1: 89/379] train loss: 0.510146 accuracy: 0.875000\n",
      "[1: 90/379] train loss: 0.446516 accuracy: 0.875000\n",
      "[1: 90/379] \u001b[94mtest\u001b[0m loss: 0.853386 accuracy: 0.687500\n",
      "[1: 91/379] train loss: 0.243185 accuracy: 1.000000\n",
      "[1: 92/379] train loss: 0.732539 accuracy: 0.750000\n",
      "[1: 93/379] train loss: 0.516287 accuracy: 0.843750\n",
      "[1: 94/379] train loss: 0.368633 accuracy: 0.937500\n",
      "[1: 95/379] train loss: 0.364511 accuracy: 0.937500\n",
      "[1: 96/379] train loss: 0.447638 accuracy: 0.875000\n",
      "[1: 97/379] train loss: 0.674384 accuracy: 0.875000\n",
      "[1: 98/379] train loss: 0.428312 accuracy: 0.906250\n",
      "[1: 99/379] train loss: 0.700944 accuracy: 0.781250\n",
      "[1: 100/379] train loss: 0.661884 accuracy: 0.781250\n",
      "[1: 100/379] \u001b[94mtest\u001b[0m loss: 0.540165 accuracy: 0.812500\n",
      "[1: 101/379] train loss: 0.775834 accuracy: 0.812500\n",
      "[1: 102/379] train loss: 0.319208 accuracy: 0.906250\n",
      "[1: 103/379] train loss: 0.540484 accuracy: 0.843750\n",
      "[1: 104/379] train loss: 0.505397 accuracy: 0.875000\n",
      "[1: 105/379] train loss: 0.513458 accuracy: 0.843750\n",
      "[1: 106/379] train loss: 0.639395 accuracy: 0.812500\n",
      "[1: 107/379] train loss: 0.850842 accuracy: 0.750000\n",
      "[1: 108/379] train loss: 0.536645 accuracy: 0.812500\n",
      "[1: 109/379] train loss: 0.521720 accuracy: 0.843750\n",
      "[1: 110/379] train loss: 0.520286 accuracy: 0.906250\n",
      "[1: 110/379] \u001b[94mtest\u001b[0m loss: 0.607728 accuracy: 0.812500\n",
      "[1: 111/379] train loss: 0.557110 accuracy: 0.781250\n",
      "[1: 112/379] train loss: 0.233574 accuracy: 0.937500\n",
      "[1: 113/379] train loss: 0.625496 accuracy: 0.812500\n",
      "[1: 114/379] train loss: 0.561570 accuracy: 0.843750\n",
      "[1: 115/379] train loss: 0.451430 accuracy: 0.875000\n",
      "[1: 116/379] train loss: 0.387947 accuracy: 0.906250\n",
      "[1: 117/379] train loss: 0.632217 accuracy: 0.843750\n",
      "[1: 118/379] train loss: 0.386277 accuracy: 0.875000\n",
      "[1: 119/379] train loss: 0.446587 accuracy: 0.875000\n",
      "[1: 120/379] train loss: 0.360261 accuracy: 0.937500\n",
      "[1: 120/379] \u001b[94mtest\u001b[0m loss: 0.513692 accuracy: 0.906250\n",
      "[1: 121/379] train loss: 0.275315 accuracy: 0.937500\n",
      "[1: 122/379] train loss: 0.714763 accuracy: 0.875000\n",
      "[1: 123/379] train loss: 0.261240 accuracy: 0.937500\n",
      "[1: 124/379] train loss: 0.346399 accuracy: 0.875000\n",
      "[1: 125/379] train loss: 0.495987 accuracy: 0.906250\n",
      "[1: 126/379] train loss: 0.518864 accuracy: 0.875000\n",
      "[1: 127/379] train loss: 0.358881 accuracy: 0.875000\n",
      "[1: 128/379] train loss: 0.722533 accuracy: 0.843750\n",
      "[1: 129/379] train loss: 0.567050 accuracy: 0.843750\n",
      "[1: 130/379] train loss: 0.608749 accuracy: 0.875000\n",
      "[1: 130/379] \u001b[94mtest\u001b[0m loss: 0.516123 accuracy: 0.843750\n",
      "[1: 131/379] train loss: 0.491134 accuracy: 0.906250\n",
      "[1: 132/379] train loss: 0.395634 accuracy: 0.875000\n",
      "[1: 133/379] train loss: 0.242337 accuracy: 0.968750\n",
      "[1: 134/379] train loss: 0.620366 accuracy: 0.843750\n",
      "[1: 135/379] train loss: 0.372801 accuracy: 0.906250\n",
      "[1: 136/379] train loss: 0.729326 accuracy: 0.781250\n",
      "[1: 137/379] train loss: 0.563920 accuracy: 0.875000\n",
      "[1: 138/379] train loss: 0.450903 accuracy: 0.906250\n",
      "[1: 139/379] train loss: 0.755382 accuracy: 0.843750\n",
      "[1: 140/379] train loss: 0.548726 accuracy: 0.843750\n",
      "[1: 140/379] \u001b[94mtest\u001b[0m loss: 0.463910 accuracy: 0.875000\n",
      "[1: 141/379] train loss: 0.322646 accuracy: 0.875000\n",
      "[1: 142/379] train loss: 0.538702 accuracy: 0.781250\n",
      "[1: 143/379] train loss: 0.467533 accuracy: 0.875000\n",
      "[1: 144/379] train loss: 0.352417 accuracy: 0.937500\n",
      "[1: 145/379] train loss: 0.437097 accuracy: 0.843750\n",
      "[1: 146/379] train loss: 0.446301 accuracy: 0.875000\n",
      "[1: 147/379] train loss: 0.517829 accuracy: 0.843750\n",
      "[1: 148/379] train loss: 0.781316 accuracy: 0.718750\n",
      "[1: 149/379] train loss: 0.199245 accuracy: 0.968750\n",
      "[1: 150/379] train loss: 0.172066 accuracy: 1.000000\n",
      "[1: 150/379] \u001b[94mtest\u001b[0m loss: 0.698156 accuracy: 0.781250\n",
      "[1: 151/379] train loss: 0.338604 accuracy: 0.937500\n",
      "[1: 152/379] train loss: 0.505332 accuracy: 0.843750\n",
      "[1: 153/379] train loss: 0.655737 accuracy: 0.843750\n",
      "[1: 154/379] train loss: 0.378104 accuracy: 0.906250\n",
      "[1: 155/379] train loss: 0.453525 accuracy: 0.906250\n",
      "[1: 156/379] train loss: 0.605345 accuracy: 0.843750\n",
      "[1: 157/379] train loss: 0.814486 accuracy: 0.750000\n",
      "[1: 158/379] train loss: 0.377191 accuracy: 0.906250\n",
      "[1: 159/379] train loss: 0.280389 accuracy: 0.937500\n",
      "[1: 160/379] train loss: 0.758001 accuracy: 0.781250\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "#from pointnet.dataset import ShapeNetDataset, ModelNetDataset\n",
    "#from pointnet.model import PointNetCls, feature_transform_regularizer\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "#ipdb.set_trace(context=5)\n",
    "#parser = argparse.ArgumentParser()\n",
    "#parser.add_argument(\n",
    "#    '--batchSize', type=int, default=32, help='input batch size')\n",
    "#parser.add_argument(\n",
    "#    '--num_points', type=int, default=2500, help='input batch size')\n",
    "#parser.add_argument(\n",
    "#    '--workers', type=int, help='number of data loading workers', default=4)\n",
    "#parser.add_argument(\n",
    "#    '--nepoch', type=int, default=250, help='number of epochs to train for')\n",
    "#parser.add_argument('--outf', type=str, default='cls', help='output folder')\n",
    "#parser.add_argument('--model', type=str, default='', help='model path')\n",
    "#parser.add_argument('--dataset', type=str, required=True, help=\"dataset path\")\n",
    "#parser.add_argument('--dataset_type', type=str, default='shapenet', help=\"dataset type shapenet|modelnet40\")\n",
    "#parser.add_argument('--feature_transform', action='store_true', help=\"use feature transform\")\n",
    "\n",
    "#ipdb.set_trace(context=5)\n",
    "#parser = argparse.ArgumentParser()\n",
    "\n",
    "\n",
    "#opt = parser.parse_args()\n",
    "\n",
    "class opt:\n",
    "  pass\n",
    "\n",
    "opt.batchSize=32\n",
    "opt.num_points=200\n",
    "opt.workers=1\n",
    "opt.nepoch=10\n",
    "opt.outf='cls'\n",
    "opt.model=''\n",
    "\n",
    "\n",
    "opt.dataset='./shapenetcore_partanno_segmentation_benchmark_v0'\n",
    "opt.dataset_type='shapenet'\n",
    "'''\n",
    "opt.dataset='./ModelNet40'\n",
    "opt.dataset_type='modelnet40'\n",
    "'''\n",
    "\n",
    "opt.feature_transform='store_true'\n",
    "\n",
    "\n",
    "print(opt)\n",
    "\n",
    "blue = lambda x: '\\033[94m' + x + '\\033[0m'\n",
    "\n",
    "opt.manualSeed = random.randint(1, 10000)  # fix seed\n",
    "print(\"Random Seed: \", opt.manualSeed)\n",
    "random.seed(opt.manualSeed)\n",
    "torch.manual_seed(opt.manualSeed)\n",
    "\n",
    "if opt.dataset_type == 'shapenet':\n",
    "    dataset = ShapeNetDataset(\n",
    "        root=opt.dataset,\n",
    "        classification=True,\n",
    "        npoints=opt.num_points)\n",
    "\n",
    "    test_dataset = ShapeNetDataset(\n",
    "        root=opt.dataset,\n",
    "        classification=True,\n",
    "        split='test',\n",
    "        npoints=opt.num_points,\n",
    "        data_augmentation=False)\n",
    "elif opt.dataset_type == 'modelnet40':\n",
    "    dataset = ModelNetDataset(\n",
    "        root=opt.dataset,\n",
    "        npoints=opt.num_points,\n",
    "        split='train')\n",
    "\n",
    "    test_dataset = ModelNetDataset(\n",
    "        root=opt.dataset,\n",
    "        split='test',\n",
    "        npoints=opt.num_points,\n",
    "        data_augmentation=False)\n",
    "else:\n",
    "    exit('wrong dataset type')\n",
    "\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=opt.batchSize,\n",
    "    shuffle=True,\n",
    "    num_workers=int(opt.workers))\n",
    "\n",
    "testdataloader = torch.utils.data.DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=opt.batchSize,\n",
    "        shuffle=True,\n",
    "        num_workers=int(opt.workers))\n",
    "\n",
    "print(len(dataset), len(test_dataset))\n",
    "num_classes = len(dataset.classes)\n",
    "print('classes', num_classes)\n",
    "\n",
    "try:\n",
    "    os.makedirs(opt.outf)\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "classifier = PointNetCls(k=num_classes, feature_transform=opt.feature_transform)\n",
    "\n",
    "if opt.model != '':\n",
    "    classifier.load_state_dict(torch.load(opt.model))\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=0.001, betas=(0.9, 0.999))\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)\n",
    "classifier.cuda()\n",
    "#ipdb.set_trace(context=5)#\n",
    "num_batch = np.floor(len(dataset) / opt.batchSize)\n",
    "ipdb.set_trace(context=5)#\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(opt.nepoch):\n",
    "    scheduler.step()\n",
    "    #ipdb.set_trace(context=5)#\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        #ipdb.set_trace(context=5)#\n",
    "        points, target = data\n",
    "        #ipdb.set_trace(context=5)#\n",
    "        target = target[:, 0]\n",
    "        points = points.transpose(2, 1)\n",
    "        points, target = points.cuda(), target.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        classifier = classifier.train()\n",
    "        pred, trans, trans_feat = classifier(points)\n",
    "        #ipdb.set_trace(context=5)#\n",
    "        loss = F.nll_loss(pred, target)\n",
    "        if opt.feature_transform:\n",
    "            loss += feature_transform_regularizer(trans_feat) * 0.001\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        pred_choice = pred.data.max(1)[1]\n",
    "        correct = pred_choice.eq(target.data).cpu().sum()\n",
    "        print('[%d: %d/%d] train loss: %f accuracy: %f' % (epoch, i, num_batch, loss.item(), correct.item() / float(opt.batchSize)))\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            j, data = next(enumerate(testdataloader, 0))\n",
    "            points, target = data\n",
    "            target = target[:, 0]\n",
    "            points = points.transpose(2, 1)\n",
    "            points, target = points.cuda(), target.cuda()\n",
    "            classifier = classifier.eval()\n",
    "            pred, _, _ = classifier(points)\n",
    "            loss = F.nll_loss(pred, target)\n",
    "            pred_choice = pred.data.max(1)[1]\n",
    "            correct = pred_choice.eq(target.data).cpu().sum()\n",
    "            print('[%d: %d/%d] %s loss: %f accuracy: %f' % (epoch, i, num_batch, blue('test'), loss.item(), correct.item()/float(opt.batchSize)))\n",
    "\n",
    "    torch.save(classifier.state_dict(), '%s/cls_model_%d.pth' % (opt.outf, epoch))\n",
    "\n",
    "total_correct = 0\n",
    "total_testset = 0\n",
    "for i,data in tqdm(enumerate(testdataloader, 0)):\n",
    "    points, target = data\n",
    "    target = target[:, 0]\n",
    "    points = points.transpose(2, 1)\n",
    "    points, target = points.cuda(), target.cuda()\n",
    "    classifier = classifier.eval()\n",
    "    pred, _, _ = classifier(points)\n",
    "    pred_choice = pred.data.max(1)[1]\n",
    "    correct = pred_choice.eq(target.data).cpu().sum()\n",
    "    total_correct += correct.item()\n",
    "    total_testset += points.size()[0]\n",
    "\n",
    "print(\"final accuracy {}\".format(total_correct / float(total_testset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xa4N4m8nalxL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DGtjjY5xNV1F",
    "outputId": "bc052a0e-c45f-4728-fd03-a77fc3e1ce8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Dec 14 13:26:50 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   77C    P0    32W /  70W |   1464MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AyT2T2o8st4F",
    "outputId": "d67cb8fb-ca15-4d0a-c5d7-e0d061ac4b91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sofa_0646.off\n"
     ]
    }
   ],
   "source": [
    "!ls ./ModelNet40/sofa/train | grep sofa_0646.off"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
