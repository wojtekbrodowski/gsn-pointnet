{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WH_uACqHFbMT"
      },
      "source": [
        "#PYTHON INSTALACJA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gS5b819tJ3WX",
        "outputId": "0e5e296b-b376-424d-d136-969d8e342baf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 154 kB 7.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 79 kB 6.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 117 kB 15.3 MB/s \n",
            "\u001b[?25h  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for unzip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 761 kB 7.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 35.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 386 kB 52.2 MB/s \n"
          ]
        }
      ],
      "source": [
        "\n",
        "%%shell\n",
        "pip install hydra-core --upgrade --quiet\n",
        "pip install unzip --quiet\n",
        "pip install ipdb -Uqq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOmG3gHqFd4r"
      },
      "source": [
        "#PYTHON PAKIETY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V3SM_OA7JPkr"
      },
      "outputs": [],
      "source": [
        "# standardowe pakiety\n",
        "import os\n",
        "from os.path import join, isfile\n",
        "from os import listdir\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import scipy as sp\n",
        "from scipy import array, newaxis\n",
        "\n",
        "#from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import random\n",
        "import glob\n",
        "import ipdb\n",
        "from __future__ import print_function\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "# Pytorch \n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.optim as optim\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import torch.utils.data as data\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "# Hydra\n",
        "import hydra\n",
        "from hydra.utils import instantiate\n",
        "from omegaconf import DictConfig, OmegaConf\n",
        "\n",
        "# tensorboard\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import pandas as pd\n",
        "from torch.utils.tensorboard import SummaryWriter \n",
        "import seaborn as sn\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#GENERACJA PLIKÓW HYDRA"
      ],
      "metadata": {
        "id": "g7u_7DANQ6g_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aby załadować checkpoint modelu należy w pliku classification.yaml podać jako parametr `model` jeden z następujących plików:\n",
        "<br>`cls_model_own_pretrained` - własna implementacja,  \n",
        "`cls_repo_model_pretrained` - modyfikacja repozytorium"
      ],
      "metadata": {
        "id": "Qe6Ev1W-GEl2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_27BPhgYGfsk",
        "outputId": "735b4331-c6ee-405b-eed0-bfb29889d17d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "%%shell\n",
        "echo \"name: classification\n",
        "target: options\n",
        "batch_size: 32\n",
        "num_points: 1000\n",
        "num_workers: 1\n",
        "num_epochs: 2\n",
        "out_folder: 'cls'\n",
        "model: ''\n",
        "dataset: 'ModelNet40'\n",
        "feature_transform: 'store_true'\n",
        "single_batch_overfit: False\" > classification.yaml\n",
        "\n",
        "echo \"name: optimizer\n",
        "lr: 0.01\n",
        "betas: [0.9, 0.999]\" > optimizer.yaml\n",
        "\n",
        "echo \"name: scheduler\n",
        "step_size: 20\n",
        "gamma: 0.5\" > scheduler.yaml"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "confClass = OmegaConf.load('classification.yaml')\n",
        "options = instantiate(confClass)"
      ],
      "metadata": {
        "id": "KwQRIcutJoJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive/', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5uNCuBRLonDN",
        "outputId": "4e5f9f06-155d-44c1-be68-f96b11488805"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TH9ZK2tFkB8"
      },
      "source": [
        "#POBIERANIE DANYCH "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if options.dataset == 'ModelNet40':\n",
        "    ! wget http://modelnet.cs.princeton.edu/ModelNet40.zip\n",
        "    ! unzip -qq /content/ModelNet40.zip -d /content/\n",
        "    dataset_num_classes = 40\n",
        "    dataset_root = '/content/ModelNet40/'\n",
        "elif options.dataset == 'ModelNet10':\n",
        "    ! wget http://3dvision.princeton.edu/projects/2014/3DShapeNets/ModelNet10.zip\n",
        "    ! unzip -qq /content/ModelNet10.zip -d /content/\n",
        "    dataset_num_classes = 10\n",
        "    dataset_root = '/content/ModelNet10/'\n",
        "else:\n",
        "    raise ValueError(\"Wrong model name!\")"
      ],
      "metadata": {
        "id": "UpmZYCj313V5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c2f49f8-95a7-4577-907d-791e1e56d83f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-12-23 10:08:00--  http://modelnet.cs.princeton.edu/ModelNet40.zip\n",
            "Resolving modelnet.cs.princeton.edu (modelnet.cs.princeton.edu)... 128.112.136.74\n",
            "Connecting to modelnet.cs.princeton.edu (modelnet.cs.princeton.edu)|128.112.136.74|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://modelnet.cs.princeton.edu/ModelNet40.zip [following]\n",
            "--2022-12-23 10:08:00--  https://modelnet.cs.princeton.edu/ModelNet40.zip\n",
            "Connecting to modelnet.cs.princeton.edu (modelnet.cs.princeton.edu)|128.112.136.74|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2039180837 (1.9G) [application/zip]\n",
            "Saving to: ‘ModelNet40.zip’\n",
            "\n",
            "ModelNet40.zip      100%[===================>]   1.90G  42.7MB/s    in 80s     \n",
            "\n",
            "2022-12-23 10:09:21 (24.2 MB/s) - ‘ModelNet40.zip’ saved [2039180837/2039180837]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrbLLONOZkh3"
      },
      "source": [
        "#MODELNET LOADER (WŁASNA IMPLEMENTACJA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "onC4Y1QCZkIK"
      },
      "outputs": [],
      "source": [
        "class ModelNetLoader(data.Dataset):\n",
        "    def __init__(self, root, randomize_pts=True, load_faces=False, split='train', num_classes=40, numpoints=5000, batch_size=32, transform=None, target_transform=None):\n",
        "        self.root = root\n",
        "        self.numpoints = numpoints\n",
        "        self.num_classes = num_classes\n",
        "        self.batch_size = batch_size\n",
        "        self.randomize_pts = randomize_pts\n",
        "        self.load_faces = load_faces\n",
        "        self.filelist = [f1 for f1 in glob.glob(self.root + '**/*.off', recursive=True)]\n",
        "        self.trainlist = [f2 for f2 in self.filelist if \"train\" in f2]\n",
        "        self.testlist = [f3 for f3 in self.filelist if \"test\" in f3]\n",
        "        if split=='train': self.objlist = self.flist_reader(self.trainlist)\n",
        "        if split=='test': self.objlist = self.flist_reader(self.testlist)\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        impath, target = self.objlist[index]\n",
        "        myF = open(impath, 'r')\n",
        "        firstLine = myF.readline().strip()\n",
        "        if 'OFF' != firstLine[0:3]:\n",
        "            raise ValueError('Not a valid OFF header')\n",
        "        if len(firstLine) > 3:\n",
        "            n_verts, n_faces, n_edges = tuple([int(s) for s in firstLine[3:].split(' ')])\n",
        "        else:\n",
        "            n_verts, n_faces, n_edges = tuple([int(s) for s in myF.readline().strip().split(' ')])\n",
        "        verts = np.array([[float(s) for s in myF.readline().strip().split(' ')] for i_vert in range(n_verts)])\n",
        "        choice = np.random.choice(verts.shape[0], self.numpoints, replace=True)\n",
        "        if self.randomize_pts:\n",
        "          point_set = verts[choice, :]\n",
        "        else:\n",
        "          point_set = verts\n",
        "        point_set = point_set - np.expand_dims(np.mean(point_set, axis=0), 0) \n",
        "        dist = np.max(np.sqrt(np.sum(point_set ** 2, axis=1)), 0)\n",
        "        point_set = point_set / dist  \n",
        "        point_set = torch.from_numpy(point_set.astype(np.float32)).float()\n",
        "\n",
        "        if self.load_faces:\n",
        "            faces = np.array([[int(s) for s in myF.readline().strip().split(' ')][1:] for i_face in range(n_faces)])\n",
        "            return point_set, target, faces\n",
        "        else:\n",
        "            return point_set, target\n",
        "\n",
        "    def flist_reader(self, filelist):\n",
        "        classes_dirs = glob.glob(self.root + \"*/\", recursive = False)\n",
        "        classes_list = [i.split('/')[3] for i in classes_dirs]\n",
        "        classes_nums = np.linspace(0,self.num_classes-1,self.num_classes)\n",
        "        self.classes_dict = dict(zip(sorted(classes_list), classes_nums.astype(int)))\n",
        "        self.nums_dict = dict(map(reversed, self.classes_dict.items()))\n",
        "        objlist = []\n",
        "\n",
        "        for line in filelist:\n",
        "            label_start_index = line.strip().find(self.root) + len(self.root)\n",
        "            label_end_index = line.strip()[label_start_index:].find('/')\n",
        "            imlabel = line.strip()[label_start_index:label_start_index+label_end_index]\n",
        "            imlabel = self.classes_dict[imlabel]\n",
        "            impath = line\n",
        "            objlist.append( (impath, imlabel) )\n",
        "        return objlist\n",
        "\n",
        "    def __len__(self):\n",
        "      return len(self.objlist)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_IRwAlmPKgsr"
      },
      "source": [
        "##DISPLAY SINGLE OBJECT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z6MoIQvBNh7m"
      },
      "outputs": [],
      "source": [
        "def disp(vertices, target, faces, dataset, full):\n",
        "    \n",
        "    fig = plt.figure(figsize=(10, 10))\n",
        "    ax = plt.axes(projection='3d')\n",
        "    \n",
        "    V_np = np.asarray(vertices.cpu())\n",
        "    if not full:\n",
        "      ax.scatter(V_np[:, 0], V_np[:, 1], V_np[:, 2])\n",
        "    else:\n",
        "      ax.plot_trisurf(V_np[:, 0], V_np[:, 1], V_np[:, 2], triangles=faces);\n",
        "\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "    print('Etykieta klasy: {}'.format(target))\n",
        "    print(dataset.nums_dict[target])\n",
        "    print('')\n",
        "\n",
        "\n",
        "\n",
        "#test for all objects\n",
        "'''\n",
        "print(len(mdltest))\n",
        "\n",
        "for n in range(len(mdltest)):\n",
        "  xxx = mdltest[n]\n",
        "  if xxx[0].shape[0] == 0:\n",
        "    ipdb.set_trace(context=5)\n",
        "'''\n",
        "\n",
        "\n",
        "\n",
        "mdltest = ModelNetLoader(root=dataset_root, randomize_pts = False, load_faces=True)\n",
        "#mdltestR = ModelNetLoader(root=dataset_root, randomize_pts = True, load_faces=True)\n",
        "\n",
        "ind = random.randint(0, len(mdltest))\n",
        "xxx = mdltest[ind]\n",
        "#xxxR = mdltestR[ind]\n",
        "\n",
        "disp(xxx[0], xxx[1], xxx[2], mdltest, full=False)\n",
        "disp(xxx[0], xxx[1], xxx[2], mdltest, full=True)\n",
        "#disp(xxxR[0], xxxR[1], xxxR[2], mdltestR, full=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RndcfcMaQg1c"
      },
      "source": [
        "#MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BEG3IWrJrRX-"
      },
      "outputs": [],
      "source": [
        "class STN(nn.Module):\n",
        "    def __init__(self, kd=True):\n",
        "        if kd:  self.k=64; self.iden_arr=np.eye(self.k).flatten()\n",
        "        else:   self.k=3;  self.iden_arr=np.array([1, 0, 0, 0, 1, 0, 0, 0, 1]) \n",
        "        super(STN, self).__init__()\n",
        "        self.conv1 = torch.nn.Conv1d(self.k, 64, 1)\n",
        "        self.conv2 = torch.nn.Conv1d(64, 128, 1)\n",
        "        self.conv3 = torch.nn.Conv1d(128, 1024, 1)\n",
        "        self.fc1 = nn.Linear(1024, 512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, self.k*self.k)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        for x in range(5): \n",
        "          string= \"self.bn\" + str(x+1) + \"=nn.BatchNorm1d(\" + str(64*2**(x)) + \")\"\n",
        "          exec(string)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        batchsize = x.shape[0]\n",
        "        #ipdb.set_trace(context=5)\n",
        "        x = F.relu(self.bn1(self.conv1(x).transpose(2,1)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = F.relu(self.bn5(self.conv3(x)))\n",
        "        x = torch.max(x, 2, keepdim=True)[0]\n",
        "        x = x.view(-1, 1024) \n",
        "        x = F.relu(self.bn4(self.fc1(x))) \n",
        "        x = F.relu(self.bn3(self.fc2(x)))\n",
        "        x = self.fc3(x)\n",
        "        iden = torch.from_numpy(self.iden_arr.astype(np.float32)).view(1, self.k*self.k).repeat(batchsize, 1)\n",
        "        if x.is_cuda:\n",
        "            iden = iden.to(x.device)\n",
        "        x = x + iden\n",
        "        x = x.view(-1, self.k, self.k)\n",
        "        return x\n",
        "\n",
        "class PointNetfeat(nn.Module):\n",
        "    def __init__(self, global_feat = True, feature_transform = False):\n",
        "        super(PointNetfeat, self).__init__()\n",
        "        self.stn = STN(kd=False)\n",
        "        self.conv1 = torch.nn.Conv1d(3, 64, 1)\n",
        "        self.conv2 = torch.nn.Conv1d(64, 128, 1)\n",
        "        self.conv3 = torch.nn.Conv1d(128, 1024, 1)\n",
        "        self.bn1 = nn.BatchNorm1d(64)\n",
        "        self.bn2 = nn.BatchNorm1d(128)\n",
        "        self.bn3 = nn.BatchNorm1d(1024)\n",
        "        self.global_feat = global_feat\n",
        "        self.feature_transform = feature_transform\n",
        "        if self.feature_transform:\n",
        "            self.fstn = STN()\n",
        "\n",
        "    def forward(self, x):\n",
        "        n_pts = x.shape[2]\n",
        "        trans = self.stn(x)\n",
        "        x = x.transpose(2, 1)\n",
        "        x = torch.bmm(x, trans)\n",
        "        x = x.transpose(2, 1)\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "\n",
        "        if self.feature_transform:\n",
        "            trans_feat = self.fstn(x)\n",
        "            x = x.transpose(2,1)\n",
        "            x = torch.bmm(x, trans_feat)\n",
        "            x = x.transpose(2,1)\n",
        "        else:\n",
        "            trans_feat = None\n",
        "\n",
        "        pointfeat = x\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = self.bn3(self.conv3(x))\n",
        "        x = torch.max(x, 2, keepdim=True)[0]\n",
        "        x = x.view(-1, 1024)\n",
        "        if self.global_feat:\n",
        "            return x, trans, trans_feat\n",
        "        else:\n",
        "            x = x.view(-1, 1024, 1).repeat(1, 1, n_pts)\n",
        "            return torch.cat([x, pointfeat], 1), trans, trans_feat\n",
        "\n",
        "\n",
        "def feature_transform_regularizer(trans):\n",
        "    d = trans.size()[1]\n",
        "    batchsize = trans.size()[0]\n",
        "    I = torch.eye(d)[None, :, :]\n",
        "    if trans.is_cuda:\n",
        "        I = I.to(trans.device)\n",
        "    loss = torch.mean(torch.norm(torch.bmm(trans, trans.transpose(2,1)) - I, dim=(1,2)))\n",
        "    return loss\n",
        "\n",
        "class PointNetCls(nn.Module):\n",
        "    def __init__(self, k=2, feature_transform=False):\n",
        "        super(PointNetCls, self).__init__()\n",
        "        self.feature_transform = feature_transform\n",
        "        self.feat = PointNetfeat(global_feat=True, feature_transform=feature_transform)\n",
        "        self.fc1 = nn.Linear(1024, 512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, k)\n",
        "        self.dropout = nn.Dropout(p=0.3)\n",
        "        self.bn1 = nn.BatchNorm1d(512)\n",
        "        self.bn2 = nn.BatchNorm1d(256)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x, trans, trans_feat = self.feat(x)\n",
        "        x = F.relu(self.bn1(self.fc1(x)))\n",
        "        x = F.relu(self.bn2(self.dropout(self.fc2(x))))\n",
        "        x = self.fc3(x)\n",
        "        return F.log_softmax(x, dim=1), trans, trans_feat"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.randn(32,1000,3)\n",
        "permuted_tensor = tensor.permute(0,2,1)\n",
        "transposed_tensor = tensor.transpose(2, 1)\n",
        "\n",
        "print(\"Oryginalny tensor \", tensor.shape)\n",
        "print(\"Permutacja \", permuted_tensor.shape)\n",
        "print(\"Transpozycja \", transposed_tensor.shape)\n",
        "\n",
        "lin1 = nn.Linear(3, 64)           #DEF\n",
        "conv1 = nn.Conv1d(3, 64, 1)       #DEF\n",
        "\n",
        "lin1.weight = torch.nn.Parameter(conv1.weight.squeeze(2))\n",
        "lin1.bias = torch.nn.Parameter(conv1.bias)\n",
        "\n",
        "out_linear = lin1(tensor).transpose(2, 1)\n",
        "out_conv = conv1(permuted_tensor)\n",
        "\n",
        "print(\"Pierwsza warstwa liniowa (mean) \", out_linear.mean())\n",
        "print(\"Pierwsza warstwa liniowa (shape) \", out_linear.shape)\n",
        "print(\"Pierwsza warstwa konwolucyjna (mean) \", out_conv.mean())\n",
        "print(\"Pierwsza warstwa konwolucyjna (shape) \", out_conv.shape)\n",
        "\n",
        "bn1 = nn.BatchNorm1d(64)          #DEF\n",
        "\n",
        "out_bnlinear = bn1(out_linear)\n",
        "out_bnconv = bn1(out_conv)\n",
        "\n",
        "print(\"BatchNorm64 - liniowa\", out_bnlinear.shape)\n",
        "print(\"BatchNorm64 - konwolucyjna\", out_bnconv.shape)\n",
        "\n",
        "out_linearrelu = F.relu(out_bnlinear)\n",
        "out_convrelu = F.relu(out_bnconv)\n",
        "\n",
        "print(\"ReLU - liniowa\", out_linearrelu.shape)\n",
        "print(\"ReLU - konwolucyjna\", out_convrelu.shape)\n",
        "\n",
        "lin2 = nn.Linear(64, 128)         #DEF\n",
        "conv2 = nn.Conv1d(64, 128, 1)     #DEF\n",
        "\n",
        "out_2linear = lin2(out_linearrelu.transpose(2, 1)).transpose(2,1)\n",
        "out_2conv = conv2(out_convrelu)\n",
        "\n",
        "print(\"2 warstwa - liniowa\", out_2linear.shape)\n",
        "print(\"2 warstwa - konwolucyjna\", out_2conv.shape)\n",
        "\n",
        "bn2 = nn.BatchNorm1d(128)          #DEF\n",
        "\n",
        "out_2bnlinear = bn2(out_2linear)\n",
        "out_2bnconv = bn2(out_2conv)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7zDAvV0nNX2w",
        "outputId": "5e447b7d-50bf-438f-c30b-fa519046c365"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Oryginalny tensor  torch.Size([32, 1000, 3])\n",
            "Permutacja  torch.Size([32, 3, 1000])\n",
            "Transpozycja  torch.Size([32, 3, 1000])\n",
            "Pierwsza warstwa liniowa (mean)  tensor(-0.0141, grad_fn=<MeanBackward0>)\n",
            "Pierwsza warstwa liniowa (shape)  torch.Size([32, 64, 1000])\n",
            "Pierwsza warstwa konwolucyjna (mean)  tensor(-0.0141, grad_fn=<MeanBackward0>)\n",
            "Pierwsza warstwa konwolucyjna (shape)  torch.Size([32, 64, 1000])\n",
            "BatchNorm64 - liniowa torch.Size([32, 64, 1000])\n",
            "BatchNorm64 - konwolucyjna torch.Size([32, 64, 1000])\n",
            "ReLU - liniowa torch.Size([32, 64, 1000])\n",
            "ReLU - konwolucyjna torch.Size([32, 64, 1000])\n",
            "2 warstwa - liniowa torch.Size([32, 128, 1000])\n",
            "2 warstwa - konwolucyjna torch.Size([32, 128, 1000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Bz8yEL5VZP9"
      },
      "source": [
        "#TRENOWANIE (WŁASNA IMPLEMENTACJA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QVkQgB__VYML",
        "outputId": "fc5cf6e5-3f07-4523-83eb-02a04bf15620"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Seed:  7990\n",
            "Rozmiar zbioru treningowego: 8858\n",
            "Rozmiar zbioru walidacyjnego: 985\n",
            "Rozmiar zbioru testowego: 2468\n",
            "Rozmiar batcha: 32\n",
            "Liczba klas: 40\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-f6b2ef6629ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrans_feat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_transform\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-cdbc00ab7f67>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrans_feat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-cdbc00ab7f67>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mn_pts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mtrans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-cdbc00ab7f67>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m#ipdb.set_trace(context=5)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (2048x1000 and 64x128)"
          ]
        }
      ],
      "source": [
        "confOptim = OmegaConf.load('optimizer.yaml')\n",
        "confSched = OmegaConf.load('scheduler.yaml')\n",
        "\n",
        "optionsOptim = instantiate(confOptim)\n",
        "optionsSched = instantiate(confSched)\n",
        "\n",
        "blue = lambda x: '\\033[94m' + x + '\\033[0m'\n",
        "\n",
        "options.manualSeed = random.randint(1, 10000)  # fix seed\n",
        "print(\"Random Seed: \", options.manualSeed)\n",
        "random.seed(options.manualSeed)\n",
        "torch.manual_seed(options.manualSeed)\n",
        "\n",
        "dataset = ModelNetLoader(root=dataset_root, num_classes=dataset_num_classes, batch_size=options.batch_size, split='train', numpoints=options.num_points)\n",
        "testdataset = ModelNetLoader(root=dataset_root, num_classes=dataset_num_classes, batch_size=options.batch_size, split='test', numpoints=options.num_points)\n",
        "\n",
        "traindataset_size = int(len(dataset) * 0.9)\n",
        "traindataset, valdataset = random_split(dataset, [traindataset_size, len(dataset) - traindataset_size])\n",
        "\n",
        "print(\"Rozmiar zbioru treningowego: \" + str(len(traindataset)))\n",
        "print(\"Rozmiar zbioru walidacyjnego: \" + str(len(valdataset)))\n",
        "print(\"Rozmiar zbioru testowego: \" + str(len(testdataset)))\n",
        "print(\"Rozmiar batcha: \" + str(dataset.batch_size))\n",
        "print('Liczba klas: ' + str(dataset.num_classes))\n",
        "\n",
        "traindataloader = DataLoader(traindataset, batch_size=options.batch_size, num_workers=int(options.num_workers), shuffle=True)\n",
        "valdataloader = DataLoader(valdataset, batch_size=len(valdataset), num_workers=int(options.num_workers), shuffle=True)\n",
        "testdataloader = DataLoader(testdataset, batch_size=options.batch_size, num_workers=int(options.num_workers), shuffle=False)\n",
        "\n",
        "classifier = PointNetCls(k=dataset.num_classes, feature_transform=options.feature_transform)\n",
        "\n",
        "num_batch = len(traindataset) / options.batch_size\n",
        "\n",
        "try:\n",
        "    os.makedirs(options.out_folder)\n",
        "except OSError:\n",
        "    pass\n",
        "\n",
        "# CHECKPOINT MODELU UWARUNKOWANY PLIKIEM classification.yaml\n",
        "if options.model != '':\n",
        "    classifier.load_state_dict(torch.load(options.model))\n",
        "    options.num_epochs = 0\n",
        "\n",
        "optimizer = optim.Adam(classifier.parameters(), confOptim.lr, confOptim.betas)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, confSched.step_size, confSched.gamma)\n",
        "\n",
        "#classifier.to('cuda:0')\n",
        "\n",
        "if options.single_batch_overfit:\n",
        "    single_batch_overfit = torch.empty((options.batch_size, options.num_points, 3))\n",
        "    single_batch_overfit_cls = torch.empty((options.batch_size))\n",
        "    for n in range(options.batch_size):\n",
        "        item = dataset[100*n]\n",
        "        single_batch_overfit[n, :, :] = item[0]\n",
        "        single_batch_overfit_cls[n] = item[1]\n",
        "    single_batch_overfit_cls = single_batch_overfit_cls.type(torch.int64)\n",
        "\n",
        "writer = SummaryWriter()#tensorboard\n",
        "y_pred=[]\n",
        "y_true=[]\n",
        "classes = tuple([x for x in range(40)])\n",
        "i=0\n",
        "\n",
        "\n",
        "for epoch in range(options.num_epochs):\n",
        "    scheduler.step()\n",
        "    for i, data_ in enumerate(traindataloader, 0): \n",
        "        if not options.single_batch_overfit:\n",
        "          points, target = data_\n",
        "        else:\n",
        "          points, target = single_batch_overfit, single_batch_overfit_cls\n",
        "        #points = points.transpose(2, 1)\n",
        "        #points, target = points.to('cuda:0'), target.to('cuda:0')\n",
        "        optimizer.zero_grad()\n",
        "        classifier = classifier.train()\n",
        "        pred, trans, trans_feat = classifier(points)\n",
        "        loss = F.nll_loss(pred, target)\n",
        "        if options.feature_transform:\n",
        "            loss += feature_transform_regularizer(trans_feat) * 0.001\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        pred_choice = pred.data.max(1)[1]\n",
        "        correct = pred_choice.eq(target.data).cpu().sum()\n",
        "        print('Epoch %d: batch %d of %d. Train loss: %f Accuracy: %f (%i/%i)' % (epoch+1, i, num_batch, loss.item(), correct.item() / float(options.batch_size), int(correct.item()), int(options.batch_size)))\n",
        "    j, data_ = next(enumerate(valdataloader, 0))\n",
        "    if not options.single_batch_overfit:\n",
        "      points, target = data_\n",
        "    else:\n",
        "      points, target = single_batch_overfit, single_batch_overfit_cls\n",
        "    #points = points.transpose(2, 1)\n",
        "    #points, target = points.to('cuda:0'), target.to('cuda:0')\n",
        "    classifier = classifier.eval()\n",
        "    pred, _, _ = classifier(points)\n",
        "    loss = F.nll_loss(pred, target)\n",
        "    pred_choice = pred.data.max(1)[1]\n",
        "    correct = pred_choice.eq(target.data).cpu().sum()\n",
        "    print('Epoch %d: batch %d of %d. %s loss: %f Accuracy: %f' % (epoch+1, i, num_batch, blue('Validation'), loss.item(), correct.item()/float(len(valdataset))))\n",
        "    torch.save(classifier.state_dict(), '%s/cls_model_%d.pth' % (options.out_folder, epoch))\n",
        "    #tensorboard \n",
        "    y_pred.extend( (torch.max(torch.exp(pred), 1)[1]).data.cpu().numpy() )\n",
        "    y_true.extend( target.data.cpu().numpy() )\n",
        "    cf_matrix = confusion_matrix(y_true, y_pred,labels=classes)\n",
        "    df_cm = pd.DataFrame(cf_matrix/np.sum(cf_matrix) * 10,index=[i for i in classes], columns=[i for i in classes]) \n",
        "    writer.add_figure(\"Confusion matrix\", sn.heatmap(df_cm, annot=True).get_figure(), epoch)\n",
        "    writer.add_scalar('loss', loss.item(), epoch) \n",
        "    writer.add_scalar('accuracy', correct.item()/float(len(valdataset)), epoch)    \n",
        "    #\n",
        "\n",
        "\n",
        "total_correct = 0\n",
        "total_testset = 0\n",
        "print(blue(\"Testing\"))\n",
        "\n",
        "for i,data_ in tqdm(enumerate(testdataloader, 0)):\n",
        "    if not options.single_batch_overfit:\n",
        "      points, target = data_\n",
        "    else:\n",
        "      points, target = single_batch_overfit, single_batch_overfit_cls\n",
        "    points = points.transpose(2, 1)\n",
        "    points, target = points.to('cuda:0'), target.to('cuda:0')\n",
        "    classifier = classifier.eval()\n",
        "    pred, _, _ = classifier(points)\n",
        "    pred_choice = pred.data.max(1)[1]\n",
        "    correct = pred_choice.eq(target.data).cpu().sum()\n",
        "    total_correct += correct.item()\n",
        "    total_testset += points.size()[0]\n",
        "\n",
        "print(\"\\nFinal accuracy: {}\".format(total_correct / float(total_testset)))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TENSORBOARD"
      ],
      "metadata": {
        "id": "5KXWdf4A3Yan"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4C5eJwd6R1OO"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UTOhHXC6aEau"
      },
      "outputs": [],
      "source": [
        "!kill 2278"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vXek99z-R4Fb"
      },
      "outputs": [],
      "source": [
        "%tensorboard --logdir runs"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "WH_uACqHFbMT",
        "5TH9ZK2tFkB8",
        "_IRwAlmPKgsr"
      ]
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}