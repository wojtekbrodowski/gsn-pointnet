{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gS5b819tJ3WX",
    "outputId": "3cd1fba0-9d8a-4463-a062-d2916db78071"
   },
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%shell\n",
    "pip install pytorch-lightning --quiet\n",
    "pip install wandb --quiet\n",
    "pip install hydra-core --upgrade --quiet\n",
    "pip install unzip --quiet\n",
    "pip install ipdb -Uqq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "V3SM_OA7JPkr"
   },
   "outputs": [],
   "source": [
    "# standardowe pakiety\n",
    "import os\n",
    "from os.path import join, isfile\n",
    "from os import listdir\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import scipy as sp\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import random\n",
    "import glob\n",
    "import ipdb\n",
    "\n",
    "# Pytorch \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.utils.data as data\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import Compose, ToPILImage, Normalize, Resize, ToTensor\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# Pytorch Lightning related imports\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import Callback\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "import torchmetrics\n",
    "\n",
    "# Hydra\n",
    "import hydra\n",
    "from hydra.utils import instantiate\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "\n",
    "# Weights and Biases\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X_n2Oa_YO7Nr",
    "outputId": "df7e5fd2-1936-4f90-ed15-dcdbe351cb33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-12-09 08:36:52--  http://modelnet.cs.princeton.edu/ModelNet40.zip\n",
      "Resolving modelnet.cs.princeton.edu (modelnet.cs.princeton.edu)... 128.112.136.74\n",
      "Connecting to modelnet.cs.princeton.edu (modelnet.cs.princeton.edu)|128.112.136.74|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://modelnet.cs.princeton.edu/ModelNet40.zip [following]\n",
      "--2022-12-09 08:36:53--  https://modelnet.cs.princeton.edu/ModelNet40.zip\n",
      "Connecting to modelnet.cs.princeton.edu (modelnet.cs.princeton.edu)|128.112.136.74|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2039180837 (1.9G) [application/zip]\n",
      "Saving to: ‘ModelNet40.zip’\n",
      "\n",
      "ModelNet40.zip      100%[===================>]   1.90G  40.7MB/s    in 58s     \n",
      "\n",
      "2022-12-09 08:37:51 (33.6 MB/s) - ‘ModelNet40.zip’ saved [2039180837/2039180837]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! wget http://modelnet.cs.princeton.edu/ModelNet40.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rIh7Q2ZoO9F3",
    "outputId": "ca234d7f-1d20-44dc-e68c-c55171e9481c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%shell\n",
    "cd /content/\n",
    "mkdir model\n",
    "unzip -qq /content/ModelNet40.zip -d /content/model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "id": "zOueCTomepQi",
    "outputId": "5f362d0e-d70e-4ac6-f2a6-81fd8e8009b6"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m myF \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/model/ModelNet40/airplane/train/airplane_0012.off\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m#myF = open('/content/testModelNet/airplane/train/airplane_0008.off', 'r')\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m V, F \u001b[38;5;241m=\u001b[39m read_off(myF)\n\u001b[1;32m     17\u001b[0m fig \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m10\u001b[39m))\n\u001b[1;32m     19\u001b[0m ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39maxes(projection\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3d\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "def read_off(file):\n",
    "    firstLine = file.readline().strip()\n",
    "    if 'OFF' != firstLine[0:3]:\n",
    "        raise ValueError('Not a valid OFF header')\n",
    "    if len(firstLine) > 3:\n",
    "        n_verts, n_faces, n_edges = tuple([int(s) for s in firstLine[4:].split(' ')])\n",
    "    else:\n",
    "        n_verts, n_faces, n_edges = tuple([int(s) for s in file.readline().strip().split(' ')])\n",
    "    verts = [[float(s) for s in file.readline().strip().split(' ')] for i_vert in range(n_verts)]\n",
    "    #faces = [[float(s) for s in file.readline().strip().split(' ')][1:] for i_face in range(n_faces)]\n",
    "    return verts\n",
    "\n",
    "myF = open('/content/model/ModelNet40/airplane/train/airplane_0012.off', 'r')\n",
    "#myF = open('/content/testModelNet/airplane/train/airplane_0008.off', 'r')\n",
    "V, F = read_off(myF)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "\n",
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "V_np = np.asarray(V)\n",
    "xx = V_np[:, 0]\n",
    "yy = V_np[:, 1]\n",
    "zz = V_np[:, 2]\n",
    "\n",
    "ax.scatter(xx, yy, zz)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "FTJPZNSMG-7J"
   },
   "outputs": [],
   "source": [
    "def default_loader(path):\n",
    "    myF = open(path, 'r')\n",
    "    firstLine = myF.readline().strip()\n",
    "    if 'OFF' != firstLine[0:3]:\n",
    "        raise ValueError('Not a valid OFF header')\n",
    "    if len(firstLine) > 3:\n",
    "        n_verts, n_faces, n_edges = tuple([int(s) for s in firstLine[4:].split(' ')])\n",
    "    else:\n",
    "        n_verts, n_faces, n_edges = tuple([int(s) for s in myF.readline().strip().split(' ')])\n",
    "    #verts = [[torch.tensor(float(s)) for s in myF.readline().strip().split(' ')] for i_vert in range(n_verts)] #TU JEST ROBIONY TO TENSOR\n",
    "    verts = torch.tensor([[float(s) for s in myF.readline().strip().split(' ')] for i_vert in range(n_verts)])\n",
    "    \n",
    "    \n",
    "    #faces = [[int(s) for s in myF.readline().strip().split(' ')][1:] for i_face in range(n_faces)]\n",
    "    return verts\n",
    "\n",
    "def default_flist_reader(flist):\n",
    "    imlist = []\n",
    "    for line in flist:\n",
    "        main_data_folder_string = \"./model/ModelNet40/\"\n",
    "        label_start_index = line.strip().find(main_data_folder_string) + len(main_data_folder_string)\n",
    "        label_end_index = line.strip()[label_start_index:].find('/')\n",
    "        imlabel = line.strip()[label_start_index:label_start_index+label_end_index]\n",
    "        impath = line\n",
    "        imlist.append( (impath, imlabel) )\n",
    "    return imlist\n",
    "\n",
    "class ModelNetFileList(data.Dataset):\n",
    "\tdef __init__(self, root, flist, transform=None, target_transform=None,\n",
    "\t\t\tflist_reader=default_flist_reader, loader=default_loader):\n",
    "\t\tself.root   = root\n",
    "\t\tself.imlist = flist_reader(flist)\t\t\n",
    "\t\tself.transform = transform\n",
    "\t\tself.target_transform = target_transform\n",
    "\t\tself.loader = loader\n",
    "\n",
    "\tdef __getitem__(self, index):\n",
    "\t\timpath, target = self.imlist[index]\n",
    "\t\t#img = self.loader(os.path.join(self.root,impath))\n",
    "\t\tobj = self.loader(impath)\n",
    "    #if self.transform is not None:\n",
    "\t\t#\timg = self.transform(img)\n",
    "\t\t#if self.target_transform is not None:\n",
    "\t\t#\ttarget = self.target_transform(target)\n",
    "\t\treturn obj, target\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.imlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "JtPIaxNTNhZJ"
   },
   "outputs": [],
   "source": [
    "class ModelNetDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, batch_size, data_dir: str = './model/ModelNet40/'):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.num_classes = 40\n",
    "        self.imglist = [f1 for f1 in glob.glob(data_dir + '**/*.off', recursive=True)]# if isfile(join(self.data_dir, f1))]\n",
    "        self.trainlist = [f2 for f2 in self.imglist if \"train\" in f2]\n",
    "        self.testlist = [f3 for f3 in self.imglist if \"test\" in f3]\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        #training / validation\n",
    "        if stage == 'fit' or stage is None:\n",
    "            train_dataset = ModelNetFileList(root=self.data_dir, flist=self.trainlist)\n",
    "            train_dataset_size = int(len(train_dataset) * 0.9)\n",
    "            self.train_dataset, self.val_dataset = random_split(train_dataset, [train_dataset_size, len(train_dataset) - train_dataset_size])\n",
    "        #testing\n",
    "        if stage == 'test' or stage is None:\n",
    "            self.test_dataset = ModelNetFileList(root=self.data_dir, flist=self.testlist)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NHM2qHyvzfvJ",
    "outputId": "5a672b6b-8f3e-4c57-8cc8-79d2c9b021b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rozmiar zbioru: 8858\n",
      "> \u001b[0;32m<ipython-input-38-01487270e487>\u001b[0m(11)\u001b[0;36mshow_examples\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m      9 \u001b[0;31m        \u001b[0mtensor_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     10 \u001b[0;31m        \u001b[0mipdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 11 \u001b[0;31m        \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     12 \u001b[0;31m        \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprojection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'3d'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     13 \u001b[0;31m        \u001b[0mV_np\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> tensor_image.shape\n",
      "torch.Size([135, 3])\n",
      "ipdb> tensor_image.dtype\n",
      "torch.float32\n",
      "ipdb> q\n"
     ]
    }
   ],
   "source": [
    "#%pdb on\n",
    "\n",
    "sample_data = ModelNetDataModule(10)\n",
    "sample_data.setup()\n",
    "print(\"Rozmiar zbioru: \" + str(len(sample_data.train_dataset)))\n",
    "\n",
    "def show_examples(dataset, n):\n",
    "    for i in range(n):\n",
    "        tensor_image, target = random.choice(dataset)\n",
    "        ipdb.set_trace(context=5)\n",
    "        fig = plt.figure(figsize=(10, 10))\n",
    "        ax = plt.axes(projection='3d')\n",
    "        V_np = np.asarray(tensor_image)\n",
    "        #ipdb.set_trace(context=4)\n",
    "        #print(V_np.size)\n",
    "        #print(V_np)\n",
    "        xx = V_np[:, 0]\n",
    "        yy = V_np[:, 1]\n",
    "        zz = V_np[:, 2]\n",
    "        ax.scatter(xx, yy, zz)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "        print('Etykieta klasy: {}'.format(target))\n",
    "        print()\n",
    "  \n",
    "show_examples(sample_data.train_dataset, 5)\n",
    "\n",
    "#dir(sample_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "sarEePNK7Okp"
   },
   "outputs": [],
   "source": [
    "class STN3d(nn.Module):\n",
    "    def __init__(self, channel):\n",
    "        super(STN3d, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv1d(channel, 64, 1)\n",
    "        #ipdb.set_trace(context=5)\n",
    "        self.conv2 = torch.nn.Conv1d(64, 128, 1)\n",
    "        self.conv3 = torch.nn.Conv1d(128, 1024, 1)\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 9)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(64) #To jest ta normalizacja odchylenia i sredniej (?1)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "        self.bn4 = nn.BatchNorm1d(512)\n",
    "        self.bn5 = nn.BatchNorm1d(256)\n",
    "\n",
    "\n",
    "    def forward(self, y):\n",
    "        batchsize = y.batch_size\n",
    "        x = y.train_dataset\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = torch.max(x, 2, keepdim=True)[0]\n",
    "        x = x.view(-1, 1024) #to jest jakiś resize...(?2)\n",
    "        x = F.relu(self.bn4(self.fc1(x)))\n",
    "        x = F.relu(self.bn5(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        iden = Variable(torch.from_numpy(np.array([1, 0, 0, 0, 1, 0, 0, 0, 1]).astype(np.float32))).view(1, 9).repeat(\n",
    "            batchsize, 1)\n",
    "        if x.is_cuda:\n",
    "            iden = iden.cuda()\n",
    "        x = x + iden\n",
    "        x = x.view(-1, 3, 3)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 758
    },
    "id": "SLKFaJoH7kWN",
    "outputId": "90a1e8f7-60d3-479c-d0a8-90679a21cf9d"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m stn\u001b[38;5;241m=\u001b[39mSTN3d(channel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#data=torch.rand(5,3,1000)\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m dataTrans\u001b[38;5;241m=\u001b[39m\u001b[43mstn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[36], line 23\u001b[0m, in \u001b[0;36mSTN3d.forward\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m     21\u001b[0m batchsize \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mbatch_size\n\u001b[1;32m     22\u001b[0m x \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mtrain_dataset\n\u001b[0;32m---> 23\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[1;32m     24\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x)))\n\u001b[1;32m     25\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn3(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv3(x)))\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:313\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 313\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:309\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    307\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    308\u001b[0m                     _single(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 309\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: conv1d() received an invalid combination of arguments - got (Subset, Parameter, Parameter, tuple, tuple, tuple, int), but expected one of:\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, tuple of ints padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (!Subset!, !Parameter!, !Parameter!, !tuple!, !tuple!, !tuple!, int)\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, str padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (!Subset!, !Parameter!, !Parameter!, !tuple!, !tuple!, !tuple!, int)\n"
     ]
    }
   ],
   "source": [
    "stn=STN3d(channel=3)\n",
    "#data=torch.rand(5,3,1000)\n",
    "dataTrans=stn.forward(sample_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KLf01YVBQoyL"
   },
   "outputs": [],
   "source": [
    "class STN3d(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(STN3d, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv1d(3, 64, 1)\n",
    "        self.conv2 = torch.nn.Conv1d(64, 128, 1)\n",
    "        self.conv3 = torch.nn.Conv1d(128, 1024, 1)\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 9)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "        self.bn4 = nn.BatchNorm1d(512)\n",
    "        self.bn5 = nn.BatchNorm1d(256)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N_SDetaWIxsQ"
   },
   "source": [
    "```python\n",
    "class STN3d(nn.Module):\n",
    "  output:\n",
    "    stn torch.Size([32, 3, 3])global feat torch.Size([32, 1024])classification head:\n",
    "      global feat torch.Size([32, 1024])\n",
    "      point feat torch.Size([32, 1088, 2500])\n",
    "      class torch.Size([32, 5])segmentation head:\n",
    "        PointNetDenseCls(\n",
    "          (feat): PointNetfeat(\n",
    "            (stn): STN3d(\n",
    "              (conv1): Conv1d(3, 64, kernel_size=(1,), stride=(1,))\n",
    "              (conv2): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
    "              (conv3): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))\n",
    "              (mp1): MaxPool1d(kernel_size=2500, stride=2500, padding=0, dilation=1, ceil_mode=False)\n",
    "              (fc1): Linear(in_features=1024, out_features=512, bias=True)\n",
    "              (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
    "              (fc3): Linear(in_features=256, out_features=9, bias=True)\n",
    "              (relu): ReLU()\n",
    "              (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "              (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "              (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "              (bn4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "              (bn5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "            )\n",
    "            (conv1): Conv1d(3, 64, kernel_size=(1,), stride=(1,))\n",
    "            (conv2): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
    "            (conv3): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))\n",
    "            (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "            (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "            (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "            (mp1): MaxPool1d(kernel_size=2500, stride=2500, padding=0, dilation=1, ceil_mode=False)\n",
    "          )\n",
    "          (conv1): Conv1d(1088, 512, kernel_size=(1,), stride=(1,))\n",
    "          (conv2): Conv1d(512, 256, kernel_size=(1,), stride=(1,))\n",
    "          (conv3): Conv1d(256, 128, kernel_size=(1,), stride=(1,))\n",
    "          (conv4): Conv1d(128, 3, kernel_size=(1,), stride=(1,))\n",
    "          (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "          (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "          (bn3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        )\n",
    "  seg torch.Size([32, 2500, 3])\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
